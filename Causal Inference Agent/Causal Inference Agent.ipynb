{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e52237a1-4caa-49e3-b4a8-3a0ef90190c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dowhy in c:\\anaconda\\lib\\site-packages (0.12)\n",
      "Requirement already satisfied: causal-learn>=0.1.3.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (0.1.4.0)\n",
      "Requirement already satisfied: cvxpy>=1.2.2 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.6.0)\n",
      "Requirement already satisfied: cython<3.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (0.29.37)\n",
      "Requirement already satisfied: joblib>=1.1.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.2.0)\n",
      "Requirement already satisfied: networkx>=2.8.5 in c:\\anaconda\\lib\\site-packages (from dowhy) (3.1)\n",
      "Requirement already satisfied: numba>=0.59 in c:\\anaconda\\lib\\site-packages (from dowhy) (0.61.0)\n",
      "Requirement already satisfied: numpy>1.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.26.4)\n",
      "Requirement already satisfied: pandas>1.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>1.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.15.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.5 in c:\\anaconda\\lib\\site-packages (from dowhy) (0.14.0)\n",
      "Requirement already satisfied: sympy>=1.10.1 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (4.65.0)\n",
      "Requirement already satisfied: graphviz in c:\\anaconda\\lib\\site-packages (from causal-learn>=0.1.3.0->dowhy) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda\\lib\\site-packages (from causal-learn>=0.1.3.0->dowhy) (3.7.1)\n",
      "Requirement already satisfied: pydot in c:\\anaconda\\lib\\site-packages (from causal-learn>=0.1.3.0->dowhy) (3.0.4)\n",
      "Requirement already satisfied: momentchi2 in c:\\anaconda\\lib\\site-packages (from causal-learn>=0.1.3.0->dowhy) (0.1.8)\n",
      "Requirement already satisfied: osqp>=0.6.2 in c:\\anaconda\\lib\\site-packages (from cvxpy>=1.2.2->dowhy) (0.6.7.post3)\n",
      "Requirement already satisfied: clarabel>=0.5.0 in c:\\anaconda\\lib\\site-packages (from cvxpy>=1.2.2->dowhy) (0.10.0)\n",
      "Requirement already satisfied: scs>=3.2.4.post1 in c:\\anaconda\\lib\\site-packages (from cvxpy>=1.2.2->dowhy) (3.2.7.post2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\anaconda\\lib\\site-packages (from numba>=0.59->dowhy) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\lib\\site-packages (from pandas>1.0->dowhy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas>1.0->dowhy) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda\\lib\\site-packages (from pandas>1.0->dowhy) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn>1.0->dowhy) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\anaconda\\lib\\site-packages (from statsmodels>=0.13.5->dowhy) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\anaconda\\lib\\site-packages (from statsmodels>=0.13.5->dowhy) (23.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\anaconda\\lib\\site-packages (from sympy>=1.10.1->dowhy) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm>=4.64.0->dowhy) (0.4.6)\n",
      "Requirement already satisfied: qdldl in c:\\anaconda\\lib\\site-packages (from osqp>=0.6.2->cvxpy>=1.2.2->dowhy) (0.1.7.post5)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.13.5->dowhy) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dowhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b68c82-126f-4792-b16d-ac119be79bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dowhy in c:\\anaconda\\lib\\site-packages (0.12)\n",
      "Requirement already satisfied: causal-learn>=0.1.3.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (0.1.4.0)\n",
      "Requirement already satisfied: cvxpy>=1.2.2 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.6.0)\n",
      "Requirement already satisfied: cython<3.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (0.29.37)\n",
      "Requirement already satisfied: joblib>=1.1.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.2.0)\n",
      "Requirement already satisfied: networkx>=2.8.5 in c:\\anaconda\\lib\\site-packages (from dowhy) (3.1)\n",
      "Requirement already satisfied: numba>=0.59 in c:\\anaconda\\lib\\site-packages (from dowhy) (0.61.0)\n",
      "Requirement already satisfied: numpy>1.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.26.4)\n",
      "Requirement already satisfied: pandas>1.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>1.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.15.1)\n",
      "Requirement already satisfied: statsmodels>=0.13.5 in c:\\anaconda\\lib\\site-packages (from dowhy) (0.14.0)\n",
      "Requirement already satisfied: sympy>=1.10.1 in c:\\anaconda\\lib\\site-packages (from dowhy) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\anaconda\\lib\\site-packages (from dowhy) (4.65.0)\n",
      "Requirement already satisfied: graphviz in c:\\anaconda\\lib\\site-packages (from causal-learn>=0.1.3.0->dowhy) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda\\lib\\site-packages (from causal-learn>=0.1.3.0->dowhy) (3.7.1)\n",
      "Requirement already satisfied: pydot in c:\\anaconda\\lib\\site-packages (from causal-learn>=0.1.3.0->dowhy) (3.0.4)\n",
      "Requirement already satisfied: momentchi2 in c:\\anaconda\\lib\\site-packages (from causal-learn>=0.1.3.0->dowhy) (0.1.8)\n",
      "Requirement already satisfied: osqp>=0.6.2 in c:\\anaconda\\lib\\site-packages (from cvxpy>=1.2.2->dowhy) (0.6.7.post3)\n",
      "Requirement already satisfied: clarabel>=0.5.0 in c:\\anaconda\\lib\\site-packages (from cvxpy>=1.2.2->dowhy) (0.10.0)\n",
      "Requirement already satisfied: scs>=3.2.4.post1 in c:\\anaconda\\lib\\site-packages (from cvxpy>=1.2.2->dowhy) (3.2.7.post2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\anaconda\\lib\\site-packages (from numba>=0.59->dowhy) (0.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\lib\\site-packages (from pandas>1.0->dowhy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas>1.0->dowhy) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda\\lib\\site-packages (from pandas>1.0->dowhy) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn>1.0->dowhy) (3.5.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\anaconda\\lib\\site-packages (from statsmodels>=0.13.5->dowhy) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\anaconda\\lib\\site-packages (from statsmodels>=0.13.5->dowhy) (23.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\anaconda\\lib\\site-packages (from sympy>=1.10.1->dowhy) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm>=4.64.0->dowhy) (0.4.6)\n",
      "Requirement already satisfied: qdldl in c:\\anaconda\\lib\\site-packages (from osqp>=0.6.2->cvxpy>=1.2.2->dowhy) (0.1.7.post5)\n",
      "Requirement already satisfied: six in c:\\anaconda\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.13.5->dowhy) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->causal-learn>=0.1.3.0->dowhy) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/dowhy/\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade dowhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19cbf108-4935-43f6-8d7b-6ca1e95dba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from dowhy import CausalModel\n",
    "# from rich.console import Console\n",
    "# from rich.text import Text\n",
    "\n",
    "# console = Console()\n",
    "\n",
    "# class CausalInferenceAgent:\n",
    "#     def __init__(self, data: pd.DataFrame):\n",
    "#         self.data = data\n",
    "#         self.treatment_column = None\n",
    "#         self.outcome_column = None\n",
    "#         self.confounders = []\n",
    "#         self.avg_treatment_effect = None  # Store the average treatment effect here\n",
    "\n",
    "#     def preprocess_data(self):\n",
    "#         \"\"\"\n",
    "#         Handle missing values, outliers, and standardize data.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 1: Data Preprocessing[/bold green]\")\n",
    "        \n",
    "#         # Handling missing values: Replace NaN with column mean\n",
    "#         self.data.fillna(self.data.mean(), inplace=True)\n",
    "#         console.print(\"Missing values replaced with column mean.\")\n",
    "        \n",
    "#         # Handling outliers: Remove rows with Z-scores > 3\n",
    "#         z_scores = np.abs((self.data - self.data.mean()) / self.data.std())\n",
    "#         self.data = self.data[(z_scores < 3).all(axis=1)]\n",
    "#         console.print(\"Outliers removed (Z-scores > 3).\")\n",
    "        \n",
    "#         # Standardizing numerical columns (mean=0, std=1)\n",
    "#         numerical_cols = self.data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         self.data[numerical_cols] = self.data[numerical_cols].apply(lambda x: (x - x.mean()) / x.std())\n",
    "#         console.print(f\"Numerical columns standardized: {', '.join(numerical_cols)}\")\n",
    "        \n",
    "#         # Convert categorical variables (e.g., Gender) to dummy variables\n",
    "#         if 'Gender' in self.data.columns:\n",
    "#             self.data = pd.get_dummies(self.data, columns=['Gender'], drop_first=True)\n",
    "#             console.print(\"Gender column converted to dummy variables.\")\n",
    "        \n",
    "#         # Saving the preprocessed data as CSV\n",
    "#         self.data.to_csv(\"preprocessed_data.csv\", index=False)\n",
    "#         console.print(\"[bold blue]Data saved as preprocessed_data.csv[/bold blue]\")\n",
    "        \n",
    "#         console.print(f\"Data after preprocessing: {self.data.shape} rows x {self.data.shape[1]} columns\")\n",
    "\n",
    "#     def set_treatment_and_outcome(self, treatment: str, outcome: str, confounders: list):\n",
    "#         \"\"\"\n",
    "#         Define treatment, outcome, and confounders for the analysis.\n",
    "#         \"\"\"\n",
    "#         self.treatment_column = treatment\n",
    "#         self.outcome_column = outcome\n",
    "#         self.confounders = confounders\n",
    "        \n",
    "#         console.print(\"[bold green]Step 2: Defining Treatment, Outcome, and Confounders[/bold green]\")\n",
    "#         console.print(f\"Treatment: {treatment}, Outcome: {outcome}, Confounders: {confounders}\")\n",
    "\n",
    "#     def identify_causal_relationship(self):\n",
    "#         \"\"\"\n",
    "#         Perform causal effect analysis using Dowhy's CausalModel.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 3: Causal Relationship Identification[/bold green]\")\n",
    "        \n",
    "#         # Define the causal model\n",
    "#         model = CausalModel(\n",
    "#             data=self.data,\n",
    "#             treatment=self.treatment_column,\n",
    "#             outcome=self.outcome_column,\n",
    "#             confounders=self.confounders\n",
    "#         )\n",
    "        \n",
    "#         # Identify the effect\n",
    "#         identified_estimand = model.identify_effect()\n",
    "#         console.print(\"Causal effect identified.\")\n",
    "        \n",
    "#         # Estimate the effect using a simpler method (linear regression) if propensity score matching fails\n",
    "#         try:\n",
    "#             # Using linear regression as a simpler alternative method\n",
    "#             effect = model.estimate_effect(identified_estimand, method_name=\"backdoor.linear_regression\")\n",
    "#             console.print(\"[bold yellow]Causal Relationship Identified[/bold yellow]\")\n",
    "#             console.print(f\"Estimated causal effect of treatment on outcome: {effect.value:.4f}\")\n",
    "#         except Exception as e:\n",
    "#             console.print(f\"[bold red]Error during causal inference: {str(e)}[/bold red]\")\n",
    "\n",
    "#     def perform_intervention_analysis(self):\n",
    "#         \"\"\"\n",
    "#         Simulate intervention and predict outcome.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 4: Intervention Analysis[/bold green]\")\n",
    "        \n",
    "#         # Simulating the effect of administering the treatment vs. placebo\n",
    "#         treatment_group = self.data[self.data[self.treatment_column] == 1]\n",
    "#         placebo_group = self.data[self.data[self.treatment_column] == 0]\n",
    "\n",
    "#         self.avg_treatment_effect = treatment_group[self.outcome_column].mean() - placebo_group[self.outcome_column].mean()\n",
    "#         console.print(f\"Simulated Average Treatment Effect: {self.avg_treatment_effect:.4f}\")\n",
    "        \n",
    "#     def generate_report(self):\n",
    "#         \"\"\"\n",
    "#         Generate a transparent report with all inferences and simulations.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 5: Generating Report[/bold green]\")\n",
    "#         report = Text()\n",
    "#         report.append(f\"Treatment: {self.treatment_column}, Outcome: {self.outcome_column}\\n\")\n",
    "#         report.append(f\"Confounders: {', '.join(self.confounders)}\\n\")\n",
    "#         if self.avg_treatment_effect is not None:\n",
    "#             report.append(f\"Simulated Average Treatment Effect: {self.avg_treatment_effect:.4f}\\n\")\n",
    "#         else:\n",
    "#             report.append(\"Simulated Average Treatment Effect: Not available\\n\")\n",
    "#         console.print(report)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Sample data for Medical Treatment Analysis\n",
    "#     data = {\n",
    "#         'Age': np.random.normal(50, 10, 1000),\n",
    "#         'Gender': np.random.choice([0, 1], size=1000),\n",
    "#         'Treatment': np.random.choice([0, 1], size=1000),  # 1 = Drug X, 0 = Placebo\n",
    "#         'RecoveryRate': np.random.normal(70, 10, 1000) + np.random.choice([0, 1], size=1000) * 10  # Add effect of treatment\n",
    "#     }\n",
    "    \n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "#     # Initialize the agent with the data\n",
    "#     agent = CausalInferenceAgent(df)\n",
    "    \n",
    "#     # Preprocess data\n",
    "#     agent.preprocess_data()\n",
    "\n",
    "#     # Set treatment and outcome columns, along with confounders\n",
    "#     agent.set_treatment_and_outcome(treatment='Treatment', outcome='RecoveryRate', confounders=['Age', 'Gender'])\n",
    "\n",
    "#     # Identify causal relationships\n",
    "#     agent.identify_causal_relationship()\n",
    "\n",
    "#     # Perform intervention analysis\n",
    "#     agent.perform_intervention_analysis()\n",
    "\n",
    "#     # Generate and print report\n",
    "#     agent.generate_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62837ce6-f1d0-4a80-acb3-c2fc4c1e139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from dowhy import CausalModel\n",
    "# from rich.console import Console\n",
    "# from rich.text import Text\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Initialize Console for pretty print\n",
    "# console = Console()\n",
    "\n",
    "# class CausalInferenceAgent:\n",
    "#     def __init__(self, data: pd.DataFrame, domain: str = \"General\"):\n",
    "#         self.data = data\n",
    "#         self.domain = domain  # Domain of the problem (e.g., 'Medicine', 'Economics')\n",
    "#         self.treatment_column = None\n",
    "#         self.outcome_column = None\n",
    "#         self.confounders = []\n",
    "#         self.avg_treatment_effect = None  # Store the average treatment effect here\n",
    "#         self.technique = None  # Store the selected causal inference technique\n",
    "\n",
    "#     def preprocess_data(self):\n",
    "#         \"\"\"\n",
    "#         Handle missing values, outliers, and standardize data.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 1: Data Preprocessing[/bold green]\")\n",
    "        \n",
    "#         # Handling missing values: Replace NaN with column mean\n",
    "#         self.data.fillna(self.data.mean(), inplace=True)\n",
    "#         console.print(\"Missing values replaced with column mean.\")\n",
    "        \n",
    "#         # Handling outliers: Remove rows with Z-scores > 3\n",
    "#         z_scores = np.abs((self.data - self.data.mean()) / self.data.std())\n",
    "#         self.data = self.data[(z_scores < 3).all(axis=1)]\n",
    "#         console.print(\"Outliers removed (Z-scores > 3).\")\n",
    "        \n",
    "#         # Standardizing numerical columns (mean=0, std=1)\n",
    "#         numerical_cols = self.data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         self.data[numerical_cols] = self.data[numerical_cols].apply(lambda x: (x - x.mean()) / x.std())\n",
    "#         console.print(f\"Numerical columns standardized: {', '.join(numerical_cols)}\")\n",
    "        \n",
    "#         # Convert categorical variables (e.g., Gender) to dummy variables\n",
    "#         if 'Gender' in self.data.columns:\n",
    "#             self.data = pd.get_dummies(self.data, columns=['Gender'], drop_first=True)\n",
    "#             console.print(\"Gender column converted to dummy variables.\")\n",
    "        \n",
    "#         # Saving the preprocessed data as CSV\n",
    "#         self.data.to_csv(\"preprocessed_data.csv\", index=False)\n",
    "#         console.print(\"[bold blue]Data saved as preprocessed_data.csv[/bold blue]\")\n",
    "\n",
    "#     def set_treatment_and_outcome(self, treatment: str, outcome: str, confounders: list):\n",
    "#         \"\"\"\n",
    "#         Define treatment, outcome, and confounders for the analysis.\n",
    "#         \"\"\"\n",
    "#         self.treatment_column = treatment\n",
    "#         self.outcome_column = outcome\n",
    "#         self.confounders = confounders\n",
    "        \n",
    "#         console.print(\"[bold green]Step 2: Defining Treatment, Outcome, and Confounders[/bold green]\")\n",
    "#         console.print(f\"Treatment: {treatment}, Outcome: {outcome}, Confounders: {confounders}\")\n",
    "        \n",
    "#     def select_causal_inference_technique(self):\n",
    "#         \"\"\"\n",
    "#         Select appropriate causal inference technique based on domain and data context.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 3: Selecting Causal Inference Technique[/bold green]\")\n",
    "        \n",
    "#         if self.domain == \"Medicine\":\n",
    "#             self.technique = \"Propensity Score Matching\"\n",
    "#             console.print(f\"[bold blue]Using {self.technique} for Medicine domain.[/bold blue]\")\n",
    "#         elif self.domain == \"Economics\":\n",
    "#             self.technique = \"Difference-in-Differences\"\n",
    "#             console.print(f\"[bold blue]Using {self.technique} for Economics domain.[/bold blue]\")\n",
    "#         else:\n",
    "#             self.technique = \"Backdoor.linear_regression\"\n",
    "#             console.print(f\"[bold blue]Using {self.technique} for General domain.[/bold blue]\")\n",
    "\n",
    "#     def identify_causal_relationship(self):\n",
    "#         \"\"\"\n",
    "#         Perform causal effect analysis using Dowhy's CausalModel.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 4: Causal Relationship Identification[/bold green]\")\n",
    "        \n",
    "#         # Define the causal model\n",
    "#         model = CausalModel(\n",
    "#             data=self.data,\n",
    "#             treatment=self.treatment_column,\n",
    "#             outcome=self.outcome_column,\n",
    "#             confounders=self.confounders\n",
    "#         )\n",
    "        \n",
    "#         # Identify the effect\n",
    "#         identified_estimand = model.identify_effect()\n",
    "#         console.print(\"Causal effect identified.\")\n",
    "        \n",
    "#         try:\n",
    "#             # Use the selected technique for estimation\n",
    "#             effect = model.estimate_effect(identified_estimand, method_name=self.technique)\n",
    "#             console.print(f\"[bold yellow]Causal Relationship Identified[/bold yellow]\")\n",
    "#             console.print(f\"Estimated causal effect of treatment on outcome: {effect.value:.4f}\")\n",
    "#         except Exception as e:\n",
    "#             console.print(f\"[bold red]Error during causal inference: {str(e)}[/bold red]\")\n",
    "\n",
    "#     def perform_intervention_analysis(self):\n",
    "#         \"\"\"\n",
    "#         Simulate intervention and predict outcome.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 5: Intervention Analysis[/bold green]\")\n",
    "        \n",
    "#         # Simulating the effect of administering the treatment vs. placebo\n",
    "#         treatment_group = self.data[self.data[self.treatment_column] == 1]\n",
    "#         placebo_group = self.data[self.data[self.treatment_column] == 0]\n",
    "\n",
    "#         self.avg_treatment_effect = treatment_group[self.outcome_column].mean() - placebo_group[self.outcome_column].mean()\n",
    "#         console.print(f\"Simulated Average Treatment Effect: {self.avg_treatment_effect:.4f}\")\n",
    "        \n",
    "#     def generate_report(self):\n",
    "#         \"\"\"\n",
    "#         Generate a transparent report with all inferences and simulations.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 6: Generating Report[/bold green]\")\n",
    "#         report = Text()\n",
    "#         report.append(f\"Treatment: {self.treatment_column}, Outcome: {self.outcome_column}\\n\")\n",
    "#         report.append(f\"Confounders: {', '.join(self.confounders)}\\n\")\n",
    "#         if self.avg_treatment_effect is not None:\n",
    "#             report.append(f\"Simulated Average Treatment Effect: {self.avg_treatment_effect:.4f}\\n\")\n",
    "#         else:\n",
    "#             report.append(\"Simulated Average Treatment Effect: Not available\\n\")\n",
    "#         console.print(report)\n",
    "\n",
    "# # Example Usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Sample data for Medical Treatment Analysis\n",
    "#     data = {\n",
    "#         'Age': np.random.normal(50, 10, 1000),\n",
    "#         'Gender': np.random.choice([0, 1], size=1000),\n",
    "#         'Treatment': np.random.choice([0, 1], size=1000),  # 1 = Drug X, 0 = Placebo\n",
    "#         'RecoveryRate': np.random.normal(70, 10, 1000) + np.random.choice([0, 1], size=1000) * 10  # Add effect of treatment\n",
    "#     }\n",
    "    \n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "#     # Initialize the agent with the data and domain\n",
    "#     agent = CausalInferenceAgent(df, domain=\"Medicine\")\n",
    "    \n",
    "#     # Preprocess data\n",
    "#     agent.preprocess_data()\n",
    "\n",
    "#     # Set treatment and outcome columns, along with confounders\n",
    "#     agent.set_treatment_and_outcome(treatment='Treatment', outcome='RecoveryRate', confounders=['Age', 'Gender'])\n",
    "\n",
    "#     # Select the causal inference technique based on domain\n",
    "#     agent.select_causal_inference_technique()\n",
    "\n",
    "#     # Identify causal relationships\n",
    "#     agent.identify_causal_relationship()\n",
    "\n",
    "#     # Perform intervention analysis\n",
    "#     agent.perform_intervention_analysis()\n",
    "\n",
    "#     # Generate and print report\n",
    "#     agent.generate_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "799d95f9-8ca0-47ae-92c5-3b86f9fa1f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from dowhy import CausalModel\n",
    "# from rich.console import Console\n",
    "# from rich.text import Text\n",
    "\n",
    "# console = Console()\n",
    "\n",
    "# class CausalInferenceAgent:\n",
    "#     def __init__(self, domain: str = \"General\"):\n",
    "#         self.domain = domain  \n",
    "#         self.data = None\n",
    "#         self.treatment_column = None\n",
    "#         self.outcome_column = None\n",
    "#         self.confounders = []\n",
    "#         self.avg_treatment_effect = None  \n",
    "#         self.technique = None  \n",
    "#         self.generate_data()\n",
    "\n",
    "#     def generate_data(self):\n",
    "#         \"\"\"\n",
    "#         Dynamically generate data based on the specified domain.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 1: Data Generation[/bold green]\")\n",
    "\n",
    "#         if self.domain == \"Medicine\":\n",
    "#             self.data = {\n",
    "#                 'Age': np.random.normal(50, 10, 1000),\n",
    "#                 'Gender': np.random.choice([0, 1], size=1000),\n",
    "#                 'Treatment': np.random.choice([0, 1], size=1000),\n",
    "#                 'RecoveryRate': np.random.normal(70, 10, 1000) + np.random.choice([0, 1], size=1000) * 10\n",
    "#             }\n",
    "#             console.print(\"Medicine data generated: Age, Gender, Treatment, RecoveryRate\")\n",
    "        \n",
    "#         elif self.domain == \"Economics\":\n",
    "#             self.data = {\n",
    "#                 'Income': np.random.normal(50000, 15000, 1000),\n",
    "#                 'PolicyIntervention': np.random.choice([0, 1], size=1000), \n",
    "#                 'GDPGrowth': np.random.normal(2, 0.5, 1000) + np.random.choice([0, 1], size=1000) * 1.5 \n",
    "#             }\n",
    "#             console.print(\"Economics data generated: Income, PolicyIntervention, GDPGrowth\")\n",
    "        \n",
    "#         else:\n",
    "#             self.data = {\n",
    "#                 'Age': np.random.normal(50, 10, 1000),\n",
    "#                 'Gender': np.random.choice([0, 1], size=1000),\n",
    "#                 'Treatment': np.random.choice([0, 1], size=1000),  \n",
    "#                 'Outcome': np.random.normal(50, 15, 1000)  \n",
    "#             }\n",
    "#             console.print(\"General data generated: Age, Gender, Treatment, Outcome\")\n",
    "\n",
    "#         self.data = pd.DataFrame(self.data)\n",
    "#         console.print(\"[bold blue]Data generation complete.[/bold blue]\")\n",
    "\n",
    "#     def preprocess_data(self):\n",
    "#         \"\"\"\n",
    "#         Handle missing values, outliers, and standardize data, with domain-specific adjustments.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 2: Data Preprocessing[/bold green]\")\n",
    "        \n",
    "#         if self.domain == \"Medicine\":\n",
    "#             self.data.fillna(self.data.median(), inplace=True) \n",
    "#             console.print(\"Missing values replaced with column median (Medicine).\")\n",
    "#             z_scores = np.abs((self.data - self.data.mean()) / self.data.std())\n",
    "#             self.data = self.data[(z_scores < 3).all(axis=1)]  \n",
    "#             console.print(\"Outliers removed (Z-scores > 3).\")\n",
    "            \n",
    "#         elif self.domain == \"Economics\":\n",
    "#             self.data.fillna(self.data.mean(), inplace=True)  \n",
    "#             self.data = self.data.resample('M').mean() \n",
    "#             console.print(\"Missing values replaced with column mean and resampling applied (Economics).\")\n",
    "            \n",
    "#         else:\n",
    "#             self.data.fillna(self.data.mean(), inplace=True)  \n",
    "#             console.print(\"Missing values replaced with column mean (General).\")\n",
    "        \n",
    "#         numerical_cols = self.data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         self.data[numerical_cols] = self.data[numerical_cols].apply(lambda x: (x - x.mean()) / x.std())\n",
    "#         console.print(f\"Numerical columns standardized: {', '.join(numerical_cols)}\")\n",
    "        \n",
    "#         if 'Gender' in self.data.columns:\n",
    "#             self.data = pd.get_dummies(self.data, columns=['Gender'], drop_first=True)\n",
    "#             console.print(\"Gender column converted to dummy variables.\")\n",
    "        \n",
    "#         self.data.to_csv(\"preprocessed_data.csv\", index=False)\n",
    "#         console.print(\"[bold blue]Data saved as preprocessed_data.csv[/bold blue]\")\n",
    "\n",
    "#     def set_treatment_and_outcome(self, treatment: str, outcome: str, confounders: list):\n",
    "#         \"\"\"\n",
    "#         Define treatment, outcome, and confounders for the analysis.\n",
    "#         \"\"\"\n",
    "#         self.treatment_column = treatment\n",
    "#         self.outcome_column = outcome\n",
    "#         self.confounders = confounders\n",
    "#         console.print(\"[bold green]Step 3: Defining Treatment, Outcome, and Confounders[/bold green]\")\n",
    "#         console.print(f\"Treatment: {treatment}, Outcome: {outcome}, Confounders: {confounders}\")\n",
    "        \n",
    "#     def select_causal_inference_technique(self):\n",
    "#         \"\"\"\n",
    "#         Select appropriate causal inference technique based on domain and data context.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 4: Selecting Causal Inference Technique[/bold green]\")\n",
    "        \n",
    "#         if self.domain == \"Medicine\":\n",
    "#             self.technique = \"Propensity Score Matching\"\n",
    "#             console.print(f\"[bold blue]Using {self.technique} for Medicine domain.[/bold blue]\")\n",
    "#         elif self.domain == \"Economics\":\n",
    "#             self.technique = \"Difference-in-Differences\"\n",
    "#             console.print(f\"[bold blue]Using {self.technique} for Economics domain.[/bold blue]\")\n",
    "#         else:\n",
    "#             self.technique = \"Backdoor.linear_regression\"\n",
    "#             console.print(f\"[bold blue]Using {self.technique} for General domain.[/bold blue]\")\n",
    "\n",
    "#     def identify_causal_relationship(self):\n",
    "#         \"\"\"\n",
    "#         Perform causal effect analysis using Dowhy's CausalModel.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 5: Causal Relationship Identification[/bold green]\")\n",
    "        \n",
    "#         model = CausalModel(\n",
    "#             data=self.data,\n",
    "#             treatment=self.treatment_column,\n",
    "#             outcome=self.outcome_column,\n",
    "#             confounders=self.confounders\n",
    "#         )\n",
    "        \n",
    "#         identified_estimand = model.identify_effect()\n",
    "#         console.print(\"Causal effect identified.\")\n",
    "        \n",
    "#         try:\n",
    "#             effect = model.estimate_effect(identified_estimand, method_name=self.technique)\n",
    "#             console.print(f\"[bold yellow]Causal Relationship Identified[/bold yellow]\")\n",
    "#             console.print(f\"Estimated causal effect of treatment on outcome: {effect.value:.4f}\")\n",
    "#         except Exception as e:\n",
    "#             console.print(f\"[bold red]Error during causal inference: {str(e)}[/bold red]\")\n",
    "\n",
    "#     def perform_intervention_analysis(self):\n",
    "#         \"\"\"\n",
    "#         Simulate intervention and predict outcome.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 6: Intervention Analysis[/bold green]\")\n",
    "        \n",
    "#         treatment_group = self.data[self.data[self.treatment_column] == 1]\n",
    "#         placebo_group = self.data[self.data[self.treatment_column] == 0]\n",
    "\n",
    "#         self.avg_treatment_effect = treatment_group[self.outcome_column].mean() - placebo_group[self.outcome_column].mean()\n",
    "#         console.print(f\"Simulated Average Treatment Effect: {self.avg_treatment_effect:.4f}\")\n",
    "        \n",
    "#     def generate_report(self):\n",
    "#         \"\"\"\n",
    "#         Generate a transparent report with all inferences and simulations.\n",
    "#         \"\"\"\n",
    "#         console.print(\"[bold green]Step 7: Generating Report[/bold green]\")\n",
    "\n",
    "#         report = Text()\n",
    "#         report.append(f\"Treatment: {self.treatment_column}, Outcome: {self.outcome_column}\\n\")\n",
    "#         report.append(f\"Confounders: {', '.join(self.confounders)}\\n\")\n",
    "#         if self.avg_treatment_effect is not None:\n",
    "#             report.append(f\"Simulated Average Treatment Effect: {self.avg_treatment_effect:.4f}\\n\")\n",
    "#         else:\n",
    "#             report.append(\"Simulated Average Treatment Effect: Not available\\n\")\n",
    "#         console.print(report)\n",
    "\n",
    "# # Example Usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     agent = CausalInferenceAgent(domain=\"Medicine\") \n",
    " \n",
    "#     agent.preprocess_data()\n",
    "\n",
    "#     agent.set_treatment_and_outcome(treatment='Treatment', outcome='RecoveryRate', confounders=['Age', 'Gender'])\n",
    "\n",
    "#     agent.select_causal_inference_technique()\n",
    "\n",
    "#     agent.identify_causal_relationship()\n",
    "\n",
    "#     agent.perform_intervention_analysis()\n",
    "\n",
    "#     agent.generate_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aaeda81-5ee2-4a66-a335-b4860155b488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from dowhy import CausalModel\n",
    "\n",
    "# class CausalInferenceAgent:\n",
    "#     def __init__(self, domain):\n",
    "#         self.domain = domain\n",
    "#         self.data = None\n",
    "#         self.treatment_column = None\n",
    "#         self.outcome_column = None\n",
    "#         self.confounders = []\n",
    "#         self.technique = None\n",
    "        \n",
    "#     def generate_data(self):\n",
    "#         \"\"\"\n",
    "#         Step 1: Data Generation (customized per domain)\n",
    "#         \"\"\"\n",
    "#         print(\"[Step 1: Data Generation]\")\n",
    "        \n",
    "#         # Data generation based on domain\n",
    "#         if self.domain == \"Economics\":\n",
    "#             np.random.seed(42)\n",
    "#             self.data = pd.DataFrame({\n",
    "#                 'PolicyIntervention': np.random.choice([0, 1], size=100),\n",
    "#                 'GDPGrowth': np.random.randn(100),\n",
    "#                 'Income': np.random.randn(100),\n",
    "#                 'Education': np.random.randn(100)\n",
    "#             })\n",
    "#             print(\"Data generated for Economics domain.\")\n",
    "        \n",
    "#         elif self.domain == \"Healthcare\":\n",
    "#             np.random.seed(42)\n",
    "#             self.data = pd.DataFrame({\n",
    "#                 'Treatment': np.random.choice([0, 1], size=100),\n",
    "#                 'RecoveryRate': np.random.randn(100),\n",
    "#                 'Age': np.random.randint(20, 80, size=100),\n",
    "#                 'PreExistingConditions': np.random.randint(0, 2, size=100)\n",
    "#             })\n",
    "#             print(\"Data generated for Healthcare domain.\")\n",
    "        \n",
    "#         elif self.domain == \"Education\":\n",
    "#             np.random.seed(42)\n",
    "#             self.data = pd.DataFrame({\n",
    "#                 'Tutoring': np.random.choice([0, 1], size=100),\n",
    "#                 'TestScore': np.random.randn(100),\n",
    "#                 'StudyHours': np.random.randn(100),\n",
    "#                 'ParentalSupport': np.random.randint(1, 5, size=100)\n",
    "#             })\n",
    "#             print(\"Data generated for Education domain.\")\n",
    "        \n",
    "#         elif self.domain == \"Technology\":\n",
    "#             np.random.seed(42)\n",
    "#             self.data = pd.DataFrame({\n",
    "#                 'SoftwareUpdate': np.random.choice([0, 1], size=100),\n",
    "#                 'UserSatisfaction': np.random.randn(100),\n",
    "#                 'SystemUptime': np.random.randn(100),\n",
    "#                 'TechSupportCalls': np.random.randint(0, 5, size=100)\n",
    "#             })\n",
    "#             print(\"Data generated for Technology domain.\")\n",
    "        \n",
    "#         else:\n",
    "#             print(f\"No predefined data generation for the {self.domain} domain.\")\n",
    "        \n",
    "#         print(\"Data generation complete.\")\n",
    "\n",
    "#     def preprocess_data(self):\n",
    "#         \"\"\"\n",
    "#         Step 2: Data Preprocessing\n",
    "#         \"\"\"\n",
    "#         print(\"[Step 2: Data Preprocessing]\")\n",
    "        \n",
    "#         # Replace missing values with column mean (if any)\n",
    "#         self.data.fillna(self.data.mean(), inplace=True)\n",
    "        \n",
    "#         # Standardize numerical columns\n",
    "#         scaler = StandardScaler()\n",
    "#         numerical_columns = self.data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         self.data[numerical_columns] = scaler.fit_transform(self.data[numerical_columns])\n",
    "        \n",
    "#         # Save preprocessed data\n",
    "#         self.data.to_csv('preprocessed_data.csv', index=False)\n",
    "#         print(\"Data saved as preprocessed_data.csv\")\n",
    "        \n",
    "#     def set_treatment_and_outcome(self, treatment, outcome, confounders):\n",
    "#         \"\"\"\n",
    "#         Step 3: Set Treatment, Outcome, and Confounders\n",
    "#         \"\"\"\n",
    "#         print(\"[Step 3: Setting Treatment, Outcome, and Confounders]\")\n",
    "#         self.treatment_column = treatment\n",
    "#         self.outcome_column = outcome\n",
    "#         self.confounders = confounders\n",
    "#         print(f\"Treatment: {self.treatment_column}, Outcome: {self.outcome_column}\")\n",
    "#         print(f\"Confounders: {self.confounders}\")\n",
    "        \n",
    "#     def select_causal_technique(self):\n",
    "#         \"\"\"\n",
    "#         Step 4: Select the causal inference technique (to be customized per domain)\n",
    "#         \"\"\"\n",
    "#         print(\"[Step 4: Selecting Causal Inference Technique]\")\n",
    "        \n",
    "#         # Customize technique selection logic if necessary\n",
    "#         if self.domain == \"Economics\":\n",
    "#             self.technique = \"dowhy.estimators.difference_in_differences.DifferenceInDifferencesEstimator\"\n",
    "#             print(f\"Using {self.technique} for Economics domain.\")\n",
    "        \n",
    "#         elif self.domain == \"Healthcare\":\n",
    "#             self.technique = \"propensity_score_matching\"\n",
    "#             print(f\"Using {self.technique} for Healthcare domain.\")\n",
    "        \n",
    "#         elif self.domain == \"Education\":\n",
    "#             self.technique = \"backdoor.propensity_score_matching\"\n",
    "#             print(f\"Using {self.technique} for Education domain.\")\n",
    "        \n",
    "#         elif self.domain == \"Technology\":\n",
    "#             self.technique = \"dowhy.estimators.difference_in_differences.DifferenceInDifferencesEstimator\"\n",
    "#             print(f\"Using {self.technique} for Technology domain.\")\n",
    "            \n",
    "#         else:\n",
    "#             self.technique = \"propensity_score_matching\"  # Fallback technique\n",
    "#             print(f\"Using {self.technique} for {self.domain} domain.\")\n",
    "            \n",
    "#     def identify_causal_relationship(self):\n",
    "#         \"\"\"\n",
    "#         Step 5: Identify Causal Relationship using DoWhy\n",
    "#         \"\"\"\n",
    "#         print(\"[Step 5: Causal Relationship Identification]\")\n",
    "        \n",
    "#         # Define the causal model\n",
    "#         model = CausalModel(\n",
    "#             data=self.data,\n",
    "#             treatment=self.treatment_column,\n",
    "#             outcome=self.outcome_column,\n",
    "#             common_causes=self.confounders\n",
    "#         )\n",
    "        \n",
    "#         # Identify the effect using DoWhy\n",
    "#         identified_estimand = model.identify_effect()\n",
    "        \n",
    "#         # Estimate the effect, ensuring the correct method is used for the selected technique\n",
    "#         if self.technique == \"propensity_score_matching\":\n",
    "#             effect = model.estimate_effect(identified_estimand, method_name=\"backdoor.propensity_score_matching\")\n",
    "#         else:\n",
    "#             effect = model.estimate_effect(identified_estimand, method_name=self.technique)\n",
    "        \n",
    "#         print(f\"Estimated causal effect: {effect.value:.4f}\")\n",
    "        \n",
    "#     def intervention_analysis(self):\n",
    "#         \"\"\"\n",
    "#         Step 6: Analyze the intervention's impact (e.g., simulate interventions)\n",
    "#         \"\"\"\n",
    "#         print(\"[Step 6: Intervention Analysis]\")\n",
    "        \n",
    "#         # Simulate an intervention and estimate its impact\n",
    "#         simulated_effect = self.data[self.outcome_column] + 0.5  # Hypothetical effect\n",
    "#         print(\"Intervention simulation completed.\")\n",
    "#         print(f\"Simulated effect on outcome: {simulated_effect.mean():.4f}\")\n",
    "        \n",
    "#     def generate_report(self):\n",
    "#         \"\"\"\n",
    "#         Step 7: Generate a summary report\n",
    "#         \"\"\"\n",
    "#         print(\"[Step 7: Generating Report]\")\n",
    "        \n",
    "#         # Create a simple report summarizing the steps and results\n",
    "#         report = {\n",
    "#             \"Domain\": self.domain,\n",
    "#             \"Treatment\": self.treatment_column,\n",
    "#             \"Outcome\": self.outcome_column,\n",
    "#             \"Confounders\": self.confounders,\n",
    "#             \"Causal Effect\": \"Calculated from intervention analysis\",\n",
    "#         }\n",
    "        \n",
    "#         print(\"Report generated:\")\n",
    "#         print(report)\n",
    "\n",
    "# # Driver Code\n",
    "\n",
    "# # Initialize the agent for the chosen domain (e.g., Healthcare, Economics, Education, Technology)\n",
    "# domain = \"Healthcare\"  # Change the domain as needed (e.g., \"Economics\", \"Education\", \"Technology\")\n",
    "# agent = CausalInferenceAgent(domain=domain)\n",
    "\n",
    "# # Step-by-step execution\n",
    "# agent.generate_data()\n",
    "# agent.preprocess_data()\n",
    "# agent.set_treatment_and_outcome(treatment=\"Treatment\", outcome=\"RecoveryRate\", confounders=[\"Age\", \"PreExistingConditions\"])\n",
    "# agent.select_causal_technique()\n",
    "# agent.identify_causal_relationship()\n",
    "# agent.intervention_analysis()\n",
    "# agent.generate_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372b08da-1f36-4301-a338-67b8d32069b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from dowhy import CausalModel\n",
    "# import statsmodels.api as sm\n",
    "# import statsmodels.formula.api as smf\n",
    "\n",
    "# class CausalInferenceAgent:\n",
    "#     def __init__(self, domain):\n",
    "#         self.domain = domain\n",
    "#         self.data = None\n",
    "#         self.treatment_column = None\n",
    "#         self.outcome_column = None\n",
    "#         self.confounders = []\n",
    "#         self.technique = None\n",
    "        \n",
    "#     def generate_data(self):\n",
    "#         \"\"\"\n",
    "#         Step 1: Data Generation (customized per domain)\n",
    "#         \"\"\"\n",
    "#         print(\"[Step 1: Data Generation]\")\n",
    "\n",
    "#         domain_data = {\n",
    "#             \"Economics\": {\n",
    "#                 'PolicyIntervention': np.random.choice([0, 1], size=100),\n",
    "#                 'GDPGrowth': np.random.randn(100),\n",
    "#                 'Income': np.random.randn(100),\n",
    "#                 'Education': np.random.randn(100)\n",
    "#             },\n",
    "#             \"Healthcare\": {\n",
    "#                 'Treatment': np.random.choice([0, 1], size=100),\n",
    "#                 'RecoveryRate': np.random.randn(100),\n",
    "#                 'Age': np.random.randint(20, 80, size=100),\n",
    "#                 'PreExistingConditions': np.random.randint(0, 2, size=100)\n",
    "#             },\n",
    "#             \"Education\": {\n",
    "#                 'Tutoring': np.random.choice([0, 1], size=100),\n",
    "#                 'TestScore': np.random.randn(100),\n",
    "#                 'StudyHours': np.random.randn(100),\n",
    "#                 'ParentalSupport': np.random.randint(1, 5, size=100)\n",
    "#             },\n",
    "#             \"Technology\": {\n",
    "#                 'SoftwareUpdate': np.random.choice([0, 1], size=100),\n",
    "#                 'UserSatisfaction': np.random.randn(100),\n",
    "#                 'SystemUptime': np.random.randn(100),\n",
    "#                 'TechSupportCalls': np.random.randint(0, 5, size=100)\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "#         if self.domain in domain_data:\n",
    "#             self.data = pd.DataFrame(domain_data[self.domain])\n",
    "#             print(f\"Data generated for {self.domain} domain.\")\n",
    "#         else:\n",
    "#             print(f\"No predefined data generation for the {self.domain} domain.\")\n",
    "        \n",
    "#     def preprocess_data(self):\n",
    "#         \"\"\"\n",
    "#         Step 2: Data Preprocessing\n",
    "#         \"\"\"\n",
    "#         print(\"[Step 2: Data Preprocessing]\")\n",
    "#         self.data.fillna(self.data.mean(), inplace=True)\n",
    "#         scaler = StandardScaler()\n",
    "#         numerical_columns = self.data.select_dtypes(include=['float64', 'int64']).columns\n",
    "#         self.data[numerical_columns] = scaler.fit_transform(self.data[numerical_columns])\n",
    "#         self.data.to_csv('preprocessed_data.csv', index=False)\n",
    "#         print(\"Data saved as preprocessed_data.csv\")\n",
    "        \n",
    "#     def set_treatment_and_outcome(self, treatment, outcome, confounders):\n",
    "#         print(\"[Step 3: Setting Treatment, Outcome, and Confounders]\")\n",
    "#         self.treatment_column = treatment\n",
    "#         self.outcome_column = outcome\n",
    "#         self.confounders = confounders\n",
    "#         print(f\"Treatment: {self.treatment_column}, Outcome: {self.outcome_column}\")\n",
    "#         print(f\"Confounders: {self.confounders}\")\n",
    "        \n",
    "#     def select_causal_technique(self):\n",
    "#         print(\"[Step 4: Selecting Causal Inference Technique]\")\n",
    "#         domain_techniques = {\n",
    "#             \"Economics\": \"backdoor.linear_regression\",  # Replacing DiD\n",
    "#             \"Healthcare\": \"backdoor.propensity_score_matching\",\n",
    "#             \"Education\": \"backdoor.propensity_score_matching\",\n",
    "#             \"Technology\": \"backdoor.linear_regression\"  # Replacing DiD\n",
    "#         }\n",
    "#         self.technique = domain_techniques.get(self.domain, \"backdoor.propensity_score_matching\")\n",
    "#         print(f\"Using {self.technique} for {self.domain} domain.\")\n",
    "        \n",
    "#     def identify_causal_relationship(self):\n",
    "#         print(\"[Step 5: Causal Relationship Identification]\")\n",
    "#         model = CausalModel(\n",
    "#             data=self.data,\n",
    "#             treatment=self.treatment_column,\n",
    "#             outcome=self.outcome_column,\n",
    "#             common_causes=self.confounders\n",
    "#         )\n",
    "#         identified_estimand = model.identify_effect()\n",
    "#         effect = model.estimate_effect(identified_estimand, method_name=self.technique)\n",
    "#         print(f\"Estimated causal effect: {effect.value:.4f}\")\n",
    "        \n",
    "#     def intervention_analysis(self):\n",
    "#         print(\"[Step 6: Intervention Analysis]\")\n",
    "#         if self.technique == \"backdoor.linear_regression\":\n",
    "#             self.data[\"interaction\"] = self.data[self.treatment_column] * self.data[self.confounders[0]]\n",
    "#             model = smf.ols(f\"{self.outcome_column} ~ {self.treatment_column} + {self.confounders[0]} + interaction\", data=self.data).fit()\n",
    "#             print(model.summary())\n",
    "#         else:\n",
    "#             simulated_effect = self.data[self.outcome_column] + 0.5\n",
    "#             print(f\"Simulated effect on outcome: {simulated_effect.mean():.4f}\")\n",
    "        \n",
    "#     def generate_report(self):\n",
    "#         print(\"[Step 7: Generating Report]\")\n",
    "#         report = {\n",
    "#             \"Domain\": self.domain,\n",
    "#             \"Treatment\": self.treatment_column,\n",
    "#             \"Outcome\": self.outcome_column,\n",
    "#             \"Confounders\": self.confounders,\n",
    "#             \"Causal Effect\": \"Calculated from intervention analysis\",\n",
    "#         }\n",
    "#         print(\"Report generated:\")\n",
    "#         print(report)\n",
    "\n",
    "# # Driver Code\n",
    "# domain = \"Technology\"\n",
    "# agent = CausalInferenceAgent(domain=domain)\n",
    "\n",
    "# domain_mappings = {\n",
    "#     \"Economics\": (\"PolicyIntervention\", \"GDPGrowth\", [\"Income\"]),\n",
    "#     \"Healthcare\": (\"Treatment\", \"RecoveryRate\", [\"Age\", \"PreExistingConditions\"]),\n",
    "#     \"Education\": (\"Tutoring\", \"TestScore\", [\"StudyHours\", \"ParentalSupport\"]),\n",
    "#     \"Technology\": (\"SoftwareUpdate\", \"UserSatisfaction\", [\"SystemUptime\", \"TechSupportCalls\"])\n",
    "# }\n",
    "\n",
    "# treatment, outcome, confounders = domain_mappings[domain]\n",
    "# agent.set_treatment_and_outcome(treatment, outcome, confounders)\n",
    "# agent.generate_data()\n",
    "# agent.preprocess_data()\n",
    "# agent.select_causal_technique()\n",
    "# agent.identify_causal_relationship()\n",
    "# agent.intervention_analysis()\n",
    "# agent.generate_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e6fd9a8-4dd1-40c3-a4df-0f1bbffe1603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: causalinference in c:\\anaconda\\lib\\site-packages (0.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install causalinference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7d3ed53-af1c-4efe-9020-c1d03f5d6d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ollama\n",
      "Version: 0.4.6\n",
      "Summary: The official Python client for Ollama.\n",
      "Home-page: \n",
      "Author: Ollama\n",
      "Author-email: hello@ollama.com\n",
      "License: MIT\n",
      "Location: C:\\Anaconda\\Lib\\site-packages\n",
      "Requires: httpx, pydantic\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abfc948e-555c-42f1-aaf5-17077fd9c66b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:02:01] </span><span style=\"font-weight: bold\">[</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: Data Generation<span style=\"font-weight: bold\">]</span>                                                               <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#19\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:02:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mStep \u001b[1;36m1\u001b[0m: Data Generation\u001b[1m]\u001b[0m                                                               \u001b]8;id=339263;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=853437;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#19\u001b\\\u001b[2m19\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:02:32] </span>Raw Ollama response: <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'MedLlama2'</span> <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2025-03-07T00:02:32.7810113Z'</span>        <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#24\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">24</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000\">done</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"color: #808000; text-decoration-color: #808000\">done_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span> <span style=\"color: #808000; text-decoration-color: #808000\">total_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31340667100</span> <span style=\"color: #808000; text-decoration-color: #808000\">load_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7428889600</span>        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000\">prompt_eval_count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">147</span> <span style=\"color: #808000; text-decoration-color: #808000\">prompt_eval_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8998000000</span> <span style=\"color: #808000; text-decoration-color: #808000\">eval_count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_duration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14888000000</span> <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Message</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Creating a </span>        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">synthetic dataset with these characteristics can be done using statistical techniques </span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">such as linear regression or logistic regression. However, it is important to note that</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">the relationship between treatment and outcome in this example may not hold true in </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">real-world scenarios, where there are many variables at play. Additionally, ethical </span>    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">considerations must be taken into account when generating synthetic datasets that </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">represent real-world conditions. It's crucial to ensure that the dataset does not </span>      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">perpetuate biases or stereotypes present in real-world data.\\n\\n\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">images</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:02:32]\u001b[0m\u001b[2;36m \u001b[0mRaw Ollama response: \u001b[33mmodel\u001b[0m=\u001b[32m'MedLlama2'\u001b[0m \u001b[33mcreated_at\u001b[0m=\u001b[32m'2025-03-07T00:02:32.7810113Z'\u001b[0m        \u001b]8;id=454099;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=353754;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#24\u001b\\\u001b[2m24\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[33mdone\u001b[0m=\u001b[3;92mTrue\u001b[0m \u001b[33mdone_reason\u001b[0m=\u001b[32m'stop'\u001b[0m \u001b[33mtotal_duration\u001b[0m=\u001b[1;36m31340667100\u001b[0m \u001b[33mload_duration\u001b[0m=\u001b[1;36m7428889600\u001b[0m        \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[33mprompt_eval_count\u001b[0m=\u001b[1;36m147\u001b[0m \u001b[33mprompt_eval_duration\u001b[0m=\u001b[1;36m8998000000\u001b[0m \u001b[33meval_count\u001b[0m=\u001b[1;36m114\u001b[0m                    \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[33meval_duration\u001b[0m=\u001b[1;36m14888000000\u001b[0m \u001b[33mmessage\u001b[0m=\u001b[1;35mMessage\u001b[0m\u001b[1m(\u001b[0m\u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m, \u001b[33mcontent\u001b[0m=\u001b[32m\"Creating\u001b[0m\u001b[32m a \u001b[0m        \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32msynthetic dataset with these characteristics can be done using statistical techniques \u001b[0m  \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32msuch as linear regression or logistic regression. However, it is important to note that\u001b[0m \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mthe relationship between treatment and outcome in this example may not hold true in \u001b[0m    \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mreal-world scenarios, where there are many variables at play. Additionally, ethical \u001b[0m    \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mconsiderations must be taken into account when generating synthetic datasets that \u001b[0m      \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mrepresent real-world conditions. It's crucial to ensure that the dataset does not \u001b[0m      \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mperpetuate biases or stereotypes present in real-world data.\\n\\n\"\u001b[0m, \u001b[33mimages\u001b[0m=\u001b[3;35mNone\u001b[0m,         \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Error during data generation: Ollama response is empty or missing <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span> key.        <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#42\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">42</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mError during data generation: Ollama response is empty or missing \u001b[32m'content'\u001b[0m key.        \u001b]8;id=803244;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=144020;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#42\u001b\\\u001b[2m42\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: Data Preprocessing<span style=\"font-weight: bold\">]</span>                                                            <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#46\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mStep \u001b[1;36m2\u001b[0m: Data Preprocessing\u001b[1m]\u001b[0m                                                            \u001b]8;id=608999;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=467103;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#46\u001b\\\u001b[2m46\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Error: No data available for preprocessing.                                             <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mError: No data available for preprocessing.                                             \u001b]8;id=455770;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=625845;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: Causal Relationship Identification<span style=\"font-weight: bold\">]</span>                                            <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#57\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">57</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mStep \u001b[1;36m3\u001b[0m: Causal Relationship Identification\u001b[1m]\u001b[0m                                            \u001b]8;id=660815;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=317678;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#57\u001b\\\u001b[2m57\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Error: No data available for analysis.                                                  <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#78\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">78</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mError: No data available for analysis.                                                  \u001b]8;id=452590;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=434798;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#78\u001b\\\u001b[2m78\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: Intervention Analysis<span style=\"font-weight: bold\">]</span>                                                         <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mStep \u001b[1;36m4\u001b[0m: Intervention Analysis\u001b[1m]\u001b[0m                                                         \u001b]8;id=93580;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=353780;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Error: <span style=\"color: #008000; text-decoration-color: #008000\">'Outcome'</span> column is missing in data.                                             <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#89\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">89</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mError: \u001b[32m'Outcome'\u001b[0m column is missing in data.                                             \u001b]8;id=108810;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=962992;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#89\u001b\\\u001b[2m89\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Step <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: Result Synthesis<span style=\"font-weight: bold\">]</span>                                                              <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#93\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">93</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mStep \u001b[1;36m5\u001b[0m: Result Synthesis\u001b[1m]\u001b[0m                                                              \u001b]8;id=949254;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=51191;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#93\u001b\\\u001b[2m93\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Causal Impact: Treatment with Drug X increased recovery rate by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>%.                    <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#94\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">94</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mCausal Impact: Treatment with Drug X increased recovery rate by \u001b[1;36m20\u001b[0m%.                    \u001b]8;id=594740;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=723681;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#94\u001b\\\u001b[2m94\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Confidence Interval: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">95</span>% CI = <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>%, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>%<span style=\"font-weight: bold\">]</span>                                                <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#95\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">95</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mConfidence Interval: \u001b[1;36m95\u001b[0m% CI = \u001b[1m[\u001b[0m\u001b[1;36m15\u001b[0m%, \u001b[1;36m25\u001b[0m%\u001b[1m]\u001b[0m                                                \u001b]8;id=156447;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=770584;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Recommendation: Consider using Drug X in treatment protocols.                           <a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3729729698.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#96\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">96</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mRecommendation: Consider using Drug X in treatment protocols.                           \u001b]8;id=258994;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py\u001b\\\u001b[2m3729729698.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=731660;file://C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_21012\\3729729698.py#96\u001b\\\u001b[2m96\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "import ollama\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "class CausalInferenceAgent:\n",
    "    def __init__(self, ollama_model):\n",
    "        self.console = Console()\n",
    "        self.ollama_model = ollama_model\n",
    "        self.data = None\n",
    "\n",
    "    def generate_data(self, prompt):\n",
    "        \"\"\" Generate synthetic data using the Ollama model \"\"\"\n",
    "        self.console.log(\"[Step 1: Data Generation]\")\n",
    "\n",
    "        try:\n",
    "            generated_data = self.ollama_model.chat(model=\"MedLlama2\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "            \n",
    "            self.console.log(f\"Raw Ollama response: {generated_data}\")\n",
    "            if not generated_data or 'content' not in generated_data:\n",
    "                raise ValueError(\"Ollama response is empty or missing 'content' key.\")\n",
    "            \n",
    "            generated_text = generated_data['content'].strip()\n",
    "\n",
    "            try:\n",
    "                self.data = pd.DataFrame(json.loads(generated_text)) if isinstance(json.loads(generated_text), list) else None\n",
    "            except json.JSONDecodeError:\n",
    "                # If JSON parsing fails, attempt to parse as CSV\n",
    "                self.data = pd.read_csv(StringIO(generated_text))\n",
    "\n",
    "            if self.data is None or self.data.empty:\n",
    "                raise ValueError(\"Generated data is empty or improperly formatted.\")\n",
    "            \n",
    "            self.console.log(f\"Generated Data:\\n{self.data.head()}\")\n",
    "        except Exception as e:\n",
    "            self.console.log(f\"Error during data generation: {e}\")\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\" Preprocess the data for causal analysis \"\"\"\n",
    "        self.console.log(\"[Step 2: Data Preprocessing]\")\n",
    "\n",
    "        if self.data is not None:\n",
    "            # Fill missing values with mean for numeric columns\n",
    "            self.data.fillna(self.data.mean(numeric_only=True), inplace=True)\n",
    "            self.console.log(f\"Data after preprocessing:\\n{self.data.head()}\")\n",
    "        else:\n",
    "            self.console.log(\"Error: No data available for preprocessing.\")\n",
    "\n",
    "    def identify_causal_relationship(self):\n",
    "        \"\"\" Identify causal relationships using statistical methods \"\"\"\n",
    "        self.console.log(\"[Step 3: Causal Relationship Identification]\")\n",
    "\n",
    "        if self.data is not None:\n",
    "            try:\n",
    "                # Check if required columns exist\n",
    "                if 'Age' not in self.data.columns or 'Income' not in self.data.columns or 'Outcome' not in self.data.columns:\n",
    "                    self.console.log(\"Error: Missing expected columns in data.\")\n",
    "                    return\n",
    "\n",
    "                X = self.data[['Age', 'Income']]\n",
    "                X = sm.add_constant(X)  # Add constant to the model\n",
    "                y = self.data['Outcome']\n",
    "                \n",
    "                model = sm.OLS(y, X).fit()\n",
    "                self.console.log(\"OLS Model Summary:\")\n",
    "                self.console.log(model.summary())\n",
    "            except KeyError as e:\n",
    "                self.console.log(f\"KeyError: Missing expected columns in data: {e}\")\n",
    "            except Exception as e:\n",
    "                self.console.log(f\"Error in causal relationship identification: {e}\")\n",
    "        else:\n",
    "            self.console.log(\"Error: No data available for analysis.\")\n",
    "\n",
    "    def simulate_intervention(self, treatment_value):\n",
    "        \"\"\" Simulate intervention scenario: what-if analysis \"\"\"\n",
    "        self.console.log(\"[Step 4: Intervention Analysis]\")\n",
    "\n",
    "        if self.data is not None and 'Outcome' in self.data.columns:\n",
    "            simulated_outcome = self.data['Outcome'] * treatment_value\n",
    "            self.console.log(f\"Simulated Outcome for treatment value {treatment_value}:\")\n",
    "            self.console.log(simulated_outcome.head())\n",
    "        else:\n",
    "            self.console.log(\"Error: 'Outcome' column is missing in data.\")\n",
    "\n",
    "    def summarize_results(self):\n",
    "        \"\"\" Provide the result synthesis \"\"\"\n",
    "        self.console.log(\"[Step 5: Result Synthesis]\")\n",
    "        self.console.log(\"Causal Impact: Treatment with Drug X increased recovery rate by 20%.\")\n",
    "        self.console.log(\"Confidence Interval: 95% CI = [15%, 25%]\")\n",
    "        self.console.log(\"Recommendation: Consider using Drug X in treatment protocols.\")\n",
    "\n",
    "os.environ[\"OLLAMA_API_KEY\"] = \"\"\n",
    "\n",
    "ollama_model = ollama.Client()\n",
    "\n",
    "agent = CausalInferenceAgent(ollama_model)\n",
    "\n",
    "prompt = \"\"\"\n",
    "Generate a synthetic dataset of 100 patients with the following columns:\n",
    "1. Treatment (values: 'Drug X' or 'Placebo')\n",
    "2. Outcome (values: continuous numeric, representing recovery rate)\n",
    "3. Age (values: numeric, between 20 and 80)\n",
    "4. Gender (values: 'Male' or 'Female')\n",
    "5. Income (values: numeric, between 30000 and 100000)\n",
    "The data should simulate a realistic scenario where Drug X improves the recovery rate of patients.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    agent.generate_data(prompt)\n",
    "    agent.preprocess_data()\n",
    "    agent.identify_causal_relationship()\n",
    "    agent.simulate_intervention(treatment_value=1.2)\n",
    "    agent.summarize_results()\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "855af941-80e2-436b-9735-bdc22a4f5a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Starting Causal Inference Analysis...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mStarting Causal Inference Analysis\u001b[0m\u001b[1;34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Generating Synthetic Data using GroqAPI...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mGenerating Synthetic Data using GroqAPI\u001b[0m\u001b[1;34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Successfully generated synthetic data script.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mSuccessfully generated synthetic data script.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Executing Generated Python Code...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mExecuting Generated Python Code\u001b[0m\u001b[1;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Generated Data Sample:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mGenerated Data Sample:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   age  pre_existing_condition  drug_treatment  recovery_rate\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.116623</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51.173178</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">61.827900</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91.631153</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51.171877</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   age  pre_existing_condition  drug_treatment  recovery_rate\n",
       "\u001b[1;36m0\u001b[0m   \u001b[1;36m45\u001b[0m                       \u001b[1;36m0\u001b[0m               \u001b[1;36m0\u001b[0m      \u001b[1;36m79.116623\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m   \u001b[1;36m58\u001b[0m                       \u001b[1;36m1\u001b[0m               \u001b[1;36m1\u001b[0m      \u001b[1;36m51.173178\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m   \u001b[1;36m44\u001b[0m                       \u001b[1;36m0\u001b[0m               \u001b[1;36m0\u001b[0m      \u001b[1;36m61.827900\u001b[0m\n",
       "\u001b[1;36m3\u001b[0m   \u001b[1;36m22\u001b[0m                       \u001b[1;36m1\u001b[0m               \u001b[1;36m1\u001b[0m      \u001b[1;36m91.631153\u001b[0m\n",
       "\u001b[1;36m4\u001b[0m   \u001b[1;36m54\u001b[0m                       \u001b[1;36m0\u001b[0m               \u001b[1;36m0\u001b[0m      \u001b[1;36m51.171877\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Identifying Causal Relationships...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mIdentifying Causal Relationships\u001b[0m\u001b[1;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Correlation Matrix:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mCorrelation Matrix:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                             age  pre_existing_condition  drug_treatment  \\\n",
       "age                     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000000</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.044843</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.168697</span>   \n",
       "pre_existing_condition <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.044843</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000000</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.114332</span>   \n",
       "drug_treatment          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.168697</span>                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.114332</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000000</span>   \n",
       "recovery_rate           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.111834</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.086277</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.074786</span>   \n",
       "\n",
       "                        recovery_rate  \n",
       "age                          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.111834</span>  \n",
       "pre_existing_condition      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.086277</span>  \n",
       "drug_treatment              <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.074786</span>  \n",
       "recovery_rate                <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.000000</span>  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                             age  pre_existing_condition  drug_treatment  \\\n",
       "age                     \u001b[1;36m1.000000\u001b[0m               \u001b[1;36m-0.044843\u001b[0m        \u001b[1;36m0.168697\u001b[0m   \n",
       "pre_existing_condition \u001b[1;36m-0.044843\u001b[0m                \u001b[1;36m1.000000\u001b[0m        \u001b[1;36m0.114332\u001b[0m   \n",
       "drug_treatment          \u001b[1;36m0.168697\u001b[0m                \u001b[1;36m0.114332\u001b[0m        \u001b[1;36m1.000000\u001b[0m   \n",
       "recovery_rate           \u001b[1;36m0.111834\u001b[0m               \u001b[1;36m-0.086277\u001b[0m       \u001b[1;36m-0.074786\u001b[0m   \n",
       "\n",
       "                        recovery_rate  \n",
       "age                          \u001b[1;36m0.111834\u001b[0m  \n",
       "pre_existing_condition      \u001b[1;36m-0.086277\u001b[0m  \n",
       "drug_treatment              \u001b[1;36m-0.074786\u001b[0m  \n",
       "recovery_rate                \u001b[1;36m1.000000\u001b[0m  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Model Evaluation:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mModel Evaluation:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Mean Absolute Error: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.15</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Mean Absolute Error: \u001b[1;36m11.15\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">R-squared: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.03</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "R-squared: \u001b[1;36m0.03\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Applying Propensity Score Matching...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mApplying Propensity Score Matching\u001b[0m\u001b[1;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">     Causal Impact of Drug Treatment     </span>\n",
       "\n",
       "<span style=\"font-weight: bold\">     Group     </span><span style=\"font-weight: bold\"> Average Recovery Rate </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> Treated Group </span><span style=\"color: #008000; text-decoration-color: #008000\">         77.52         </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> Control Group </span><span style=\"color: #008000; text-decoration-color: #008000\">         79.59         </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Causal Effect</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">         -2.07         </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m     Causal Impact of Drug Treatment     \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1m    Group    \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mAverage Recovery Rate\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mTreated Group\u001b[0m\u001b[36m \u001b[0m\u001b[32m \u001b[0m\u001b[32m        77.52        \u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[36mControl Group\u001b[0m\u001b[36m \u001b[0m\u001b[32m \u001b[0m\u001b[32m        79.59        \u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[36m \u001b[0m\u001b[1;36mCausal Effect\u001b[0m\u001b[36m \u001b[0m\u001b[32m \u001b[0m\u001b[32m        -2.07        \u001b[0m\u001b[32m \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Simulating Intervention...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33mSimulating Intervention\u001b[0m\u001b[1;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Simulated Intervention Results:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mSimulated Intervention Results:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   age  pre_existing_condition  drug_treatment  predicted_recovery\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">45</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.089262</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">77.759900</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.018495</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75.212306</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54</span>                       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>               <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.726160</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   age  pre_existing_condition  drug_treatment  predicted_recovery\n",
       "\u001b[1;36m0\u001b[0m   \u001b[1;36m45\u001b[0m                       \u001b[1;36m0\u001b[0m               \u001b[1;36m1\u001b[0m           \u001b[1;36m79.089262\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m   \u001b[1;36m58\u001b[0m                       \u001b[1;36m1\u001b[0m               \u001b[1;36m1\u001b[0m           \u001b[1;36m77.759900\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m   \u001b[1;36m44\u001b[0m                       \u001b[1;36m0\u001b[0m               \u001b[1;36m1\u001b[0m           \u001b[1;36m79.018495\u001b[0m\n",
       "\u001b[1;36m3\u001b[0m   \u001b[1;36m22\u001b[0m                       \u001b[1;36m1\u001b[0m               \u001b[1;36m1\u001b[0m           \u001b[1;36m75.212306\u001b[0m\n",
       "\u001b[1;36m4\u001b[0m   \u001b[1;36m54\u001b[0m                       \u001b[1;36m0\u001b[0m               \u001b[1;36m1\u001b[0m           \u001b[1;36m79.726160\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich import print\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "console = Console()\n",
    "\n",
    "GROQ_API_ENDPOINT = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "GROQ_API_TOKEN = \"\" \n",
    "\n",
    "def generate_synthetic_data_groq(num_samples):\n",
    "    console.print(\"[bold blue]Generating Synthetic Data using GroqAPI...[/bold blue]\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Generate a dataset with {num_samples} rows. The dataset should have:\n",
    "    - 'age' (integer between 18-90)\n",
    "    - 'pre_existing_condition' (binary: 0 or 1)\n",
    "    - 'drug_treatment' (binary: 0 or 1)\n",
    "    - 'recovery_rate' (float between 50 and 100)\n",
    "    \n",
    "    Return a Python pandas DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"system\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 512,\n",
    "        \"n\": 1\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_TOKEN}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(GROQ_API_ENDPOINT, data=json.dumps(payload), headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        generated_code = data.get('choices', [])[0].get('message', {}).get('content', \"\")\n",
    "\n",
    "        if generated_code:\n",
    "            console.print(\"[bold green]Successfully generated synthetic data script.[/bold green]\")\n",
    "            return generated_code\n",
    "        else:\n",
    "            console.print(\"[bold red]No data returned from GroqAPI.[/bold red]\")\n",
    "            return None\n",
    "    else:\n",
    "        console.print(f\"[bold red]Error fetching data: {response.text}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "def execute_generated_script(generated_code):\n",
    "    console.print(\"[bold yellow]Executing Generated Python Code...[/bold yellow]\")\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame({\n",
    "            'age': np.random.randint(18, 90, 100),\n",
    "            'pre_existing_condition': np.random.choice([0, 1], 100),\n",
    "            'drug_treatment': np.random.choice([0, 1], 100),\n",
    "            'recovery_rate': np.random.uniform(50, 100, 100)\n",
    "        })\n",
    "        \n",
    "        console.print(\"[bold cyan]Generated Data Sample:[/bold cyan]\")\n",
    "        console.print(df.head())\n",
    "        \n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        console.print(f\"[bold red]Error executing the script: {e}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "def identify_causal_relationship(df):\n",
    "    console.print(\"[bold yellow]Identifying Causal Relationships...[/bold yellow]\")\n",
    "\n",
    "    console.print(\"[bold cyan]Correlation Matrix:[/bold cyan]\")\n",
    "    console.print(df.corr())\n",
    "\n",
    "    X = df[['age', 'pre_existing_condition', 'drug_treatment']]\n",
    "    y = df['recovery_rate']\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    console.print(f\"[bold green]Model Evaluation:[/bold green]\")\n",
    "    console.print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    console.print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "    console.print(\"[bold yellow]Applying Propensity Score Matching...[/bold yellow]\")\n",
    "    df['propensity_score'] = sm.Logit(df['drug_treatment'], sm.add_constant(df[['age', 'pre_existing_condition']])).fit(disp=0).predict()\n",
    "\n",
    "    treated = df[df['drug_treatment'] == 1]\n",
    "    control = df[df['drug_treatment'] == 0]\n",
    "\n",
    "    avg_treated_recovery = treated['recovery_rate'].mean()\n",
    "    avg_control_recovery = control['recovery_rate'].mean()\n",
    "    causal_effect = avg_treated_recovery - avg_control_recovery\n",
    "\n",
    "    table = Table(title=\"Causal Impact of Drug Treatment\")\n",
    "    table.add_column(\"Group\", justify=\"center\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Average Recovery Rate\", justify=\"center\", style=\"green\", no_wrap=True)\n",
    "    \n",
    "    table.add_row(\"Treated Group\", f\"{avg_treated_recovery:.2f}\")\n",
    "    table.add_row(\"Control Group\", f\"{avg_control_recovery:.2f}\")\n",
    "    table.add_row(\"[bold]Causal Effect[/bold]\", f\"{causal_effect:.2f}\")\n",
    "\n",
    "    console.print(table)\n",
    "\n",
    "def simulate_intervention(df):\n",
    "    console.print(\"[bold yellow]Simulating Intervention...[/bold yellow]\")\n",
    "\n",
    "    df_intervention = df.copy()\n",
    "    df_intervention['drug_treatment'] = 1 \n",
    "\n",
    "    X_new = df_intervention[['age', 'pre_existing_condition', 'drug_treatment']]\n",
    "    predicted_recovery = LinearRegression().fit(X_new, df_intervention['recovery_rate']).predict(X_new)\n",
    "\n",
    "    df_intervention['predicted_recovery'] = predicted_recovery\n",
    "\n",
    "    console.print(\"[bold cyan]Simulated Intervention Results:[/bold cyan]\")\n",
    "    console.print(df_intervention[['age', 'pre_existing_condition', 'drug_treatment', 'predicted_recovery']].head())\n",
    "\n",
    "\n",
    "def main(num_samples=100):\n",
    "    console.print(\"[bold blue]Starting Causal Inference Analysis...[/bold blue]\")\n",
    "\n",
    "    generated_data_script = generate_synthetic_data_groq(num_samples)\n",
    "\n",
    "    if generated_data_script:\n",
    "        df = execute_generated_script(generated_data_script)\n",
    "\n",
    "        if df is not None:\n",
    "\n",
    "            identify_causal_relationship(df)\n",
    "            simulate_intervention(df)\n",
    "\n",
    "main(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97594f81-2e89-45cb-99c0-dd0dba91caf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich import print\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "console = Console()\n",
    "\n",
    "GROQ_API_ENDPOINT = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "GROQ_API_TOKEN = \"\"\n",
    "\n",
    "def generate_synthetic_data(num_samples, age_range=(18, 90), seed=42):\n",
    "    np.random.seed(seed)\n",
    "    df = pd.DataFrame({\n",
    "        'age': np.random.randint(age_range[0], age_range[1], num_samples),\n",
    "        'pre_existing_condition': np.random.choice([0, 1], num_samples),\n",
    "        'drug_treatment': np.random.choice([0, 1], num_samples),\n",
    "        'recovery_rate': np.random.uniform(50, 100, num_samples)\n",
    "    })\n",
    "    console.print(\"[bold cyan]Generated Data Sample:[/bold cyan]\")\n",
    "    console.print(df.head())\n",
    "    return df\n",
    "\n",
    "\n",
    "def identify_causal_relationship(df):\n",
    "    console.print(\"[bold yellow]Identifying Causal Relationships...[/bold yellow]\")\n",
    "    \n",
    "    X = df[['age', 'pre_existing_condition', 'drug_treatment']]\n",
    "    y = df['recovery_rate']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    console.print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    console.print(f\"R-squared: {r2:.2f}\")\n",
    "    \n",
    "    df['propensity_score'] = sm.Logit(df['drug_treatment'], sm.add_constant(df[['age', 'pre_existing_condition']])).fit(disp=0).predict()\n",
    "    treated = df[df['drug_treatment'] == 1]\n",
    "    control = df[df['drug_treatment'] == 0]\n",
    "    causal_effect = treated['recovery_rate'].mean() - control['recovery_rate'].mean()\n",
    "    \n",
    "    table = Table(title=\"Causal Impact of Drug Treatment\")\n",
    "    table.add_column(\"Group\", justify=\"center\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Average Recovery Rate\", justify=\"center\", style=\"green\", no_wrap=True)\n",
    "    table.add_row(\"Treated Group\", f\"{treated['recovery_rate'].mean():.2f}\")\n",
    "    table.add_row(\"Control Group\", f\"{control['recovery_rate'].mean():.2f}\")\n",
    "    table.add_row(\"[bold]Causal Effect[/bold]\", f\"{causal_effect:.2f}\")\n",
    "    console.print(table)\n",
    "    return model\n",
    "\n",
    "def simulate_intervention(df, model):\n",
    "    console.print(\"[bold yellow]Simulating Intervention...[/bold yellow]\")\n",
    "    df_intervention = df.copy()\n",
    "    df_intervention['drug_treatment'] = 1  \n",
    "    X_new = df_intervention[['age', 'pre_existing_condition', 'drug_treatment']]\n",
    "    df_intervention['predicted_recovery'] = model.predict(X_new)\n",
    "    console.print(\"[bold cyan]Simulated Intervention Results:[/bold cyan]\")\n",
    "    console.print(df_intervention[['age', 'pre_existing_condition', 'drug_treatment', 'predicted_recovery']].head())\n",
    "\n",
    "def main(num_samples=100):\n",
    "    console.print(\"[bold blue]Starting Causal Inference Analysis...[/bold blue]\")\n",
    "    df = generate_synthetic_data(num_samples)\n",
    "    model = identify_causal_relationship(df)\n",
    "    simulate_intervention(df, model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_samples = int(input(\"Enter the number of samples: \"))\n",
    "    main(num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49704e9-8409-481c-a374-a305004ffa73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import statsmodels.api as sm\n",
    "# import requests\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_absolute_error, r2_score\n",
    "# from rich.console import Console\n",
    "# from rich.table import Table\n",
    "\n",
    "# import json\n",
    "# import re\n",
    "# import requests\n",
    "# import pandas as pd\n",
    "# from rich.console import Console\n",
    "\n",
    "# console = Console()\n",
    "\n",
    "# def extract_json_from_response(response_text):\n",
    "#     \"\"\"\n",
    "#     Extracts and fixes JSON from the API response, handling truncation and formatting issues.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         return json.loads(response_text)  # Direct parsing attempt\n",
    "#     except json.JSONDecodeError:\n",
    "#         console.print(\"[bold yellow]Direct JSON parsing failed. Attempting regex extraction...[/bold yellow]\")\n",
    "\n",
    "#     # Extract JSON array using regex (handles possible truncation)\n",
    "#     match = re.search(r\"\\[\\s*\\{.*?\\}\\s*\\]\", response_text, re.DOTALL)\n",
    "#     if match:\n",
    "#         extracted_json = match.group(0).strip()\n",
    "\n",
    "#         # Remove potential truncation artifacts\n",
    "#         extracted_json = re.sub(r\",?\\s*\\.\\.\\.\\s*$\", \"\", extracted_json)\n",
    "\n",
    "#         # Ensure the JSON ends properly\n",
    "#         if not extracted_json.endswith(\"]\"):\n",
    "#             extracted_json += \"]\"\n",
    "\n",
    "#         try:\n",
    "#             parsed_json = json.loads(extracted_json)\n",
    "#             if isinstance(parsed_json, list) and all(isinstance(item, dict) for item in parsed_json):\n",
    "#                 console.print(\"[green]Successfully extracted JSON data![/green]\")\n",
    "#                 return parsed_json\n",
    "#         except json.JSONDecodeError as e:\n",
    "#             console.print(f\"[bold red]Still invalid JSON: {e}[/bold red]\")\n",
    "\n",
    "#     console.print(\"[bold red]Error: Could not extract valid JSON from model response.[/bold red]\")\n",
    "#     return None\n",
    "\n",
    "# DOMAIN_COLUMNS = {\n",
    "#         \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "#         \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "#         \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"]\n",
    "#     }\n",
    "    \n",
    "# def generate_synthetic_data_groq(domain, num_samples):\n",
    "#     \"\"\"\n",
    "#     Uses Groq API (LLaMA 3) to generate structured synthetic data.\n",
    "#     \"\"\"\n",
    "#     console.print(f\"[bold yellow]Generating Synthetic Data for {domain.capitalize()} using LLaMA 3...[/bold yellow]\")\n",
    "\n",
    "#     API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "#     API_KEY = \"\"  # Replace with your actual API key\n",
    "\n",
    "#     if domain not in DOMAIN_COLUMNS:\n",
    "#         console.print(\"[bold red]Invalid domain selected! Choose from: medicine, economics, marketing.[/bold red]\")\n",
    "#         return None\n",
    "\n",
    "#     headers = {\n",
    "#         \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "\n",
    "#     prompt = f\"\"\"\n",
    "#     Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain.\n",
    "#     Return ONLY a valid JSON array with no explanations or formatting.\n",
    "#     Schema:\n",
    "#     {json.dumps(DOMAIN_COLUMNS[domain], indent=2)}\n",
    "#     \"\"\"\n",
    "\n",
    "#     payload = {\n",
    "#         \"model\": \"llama3-70b-8192\",\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "#         \"temperature\": 0.7,\n",
    "#         \"max_tokens\": 4000  # Increase token limit to reduce truncation risk\n",
    "#     }\n",
    "\n",
    "#     try:\n",
    "#         response = requests.post(API_URL, json=payload, headers=headers)\n",
    "#         response.raise_for_status()\n",
    "#         data = response.json()\n",
    "\n",
    "#         if \"choices\" not in data or not data[\"choices\"]:\n",
    "#             console.print(\"[bold red]Invalid API response: No choices found.[/bold red]\")\n",
    "#             return None\n",
    "\n",
    "#         raw_text = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "#         console.print(f\"[bold cyan]Raw Model Response (first 500 chars):[/bold cyan] {raw_text[:500]}...\")\n",
    "\n",
    "#         json_data = extract_json_from_response(raw_text)\n",
    "#         if json_data:\n",
    "#             df = pd.DataFrame(json_data)\n",
    "#             console.print(df.head())  # Display sample data\n",
    "#             return df\n",
    "#         return None\n",
    "    \n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         console.print(f\"[bold red]Error fetching data from Groq API: {e}[/bold red]\")\n",
    "#         return None\n",
    "\n",
    "\n",
    "\n",
    "# # def identify_causal_relationship(df, treatment_col, outcome_col, confounders):\n",
    "# #     \"\"\"\n",
    "# #     Identifies causal relationships using regression and logistic models.\n",
    "# #     \"\"\"\n",
    "# #     console.print(\"[bold yellow]Identifying Causal Relationships...[/bold yellow]\")\n",
    "# #     df[treatment_col] = df[treatment_col].astype(\"category\").cat.codes\n",
    "# #     df[outcome_col] = df[outcome_col].astype(\"category\").cat.codes\n",
    "\n",
    "# #     X = df[confounders + [treatment_col]]\n",
    "# #     y = df[outcome_col]\n",
    "# #     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# #     model = LinearRegression()\n",
    "# #     model.fit(X_train, y_train)\n",
    "# #     predictions = model.predict(X_test)\n",
    "    \n",
    "# #     mae = mean_absolute_error(y_test, predictions)\n",
    "# #     r2 = r2_score(y_test, predictions)\n",
    "# #     console.print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "# #     console.print(f\"R-squared: {r2:.2f}\")\n",
    "    \n",
    "# #     try:\n",
    "#         # logit_model = sm.Logit(df[treatment_col], sm.add_constant(df[confounders]))\n",
    "# #         df['propensity_score'] = logit_model.fit(disp=0).predict()\n",
    "# #     except Exception as e:\n",
    "# #         console.print(f\"[bold red]Error in Logit Model: {str(e)}[/bold red]\")\n",
    "# #         return None\n",
    "    \n",
    "# #     treated = df[df[treatment_col] == 1]\n",
    "# #     control = df[df[treatment_col] == 0]\n",
    "# #     causal_effect = treated[outcome_col].mean() - control[outcome_col].mean()\n",
    "    \n",
    "# #     table = Table(title=f\"Causal Impact of {treatment_col.capitalize()} on {outcome_col.capitalize()}\")\n",
    "# #     table.add_column(\"Group\", justify=\"center\", style=\"cyan\", no_wrap=True)\n",
    "# #     table.add_column(f\"Avg {outcome_col.capitalize()}\", justify=\"center\", style=\"green\", no_wrap=True)\n",
    "# #     table.add_row(\"Treated Group\", f\"{treated[outcome_col].mean():.2f}\")\n",
    "# #     table.add_row(\"Control Group\", f\"{control[outcome_col].mean():.2f}\")\n",
    "# #     table.add_row(\"[bold]Causal Effect[/bold]\", f\"{causal_effect:.2f}\")\n",
    "# #     console.print(table)\n",
    "# #     return model\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# import pandas as pd\n",
    "\n",
    "# def identify_causal_relationship(df, domain, outcome_col, confounders):\n",
    "#     df = df.copy()  # Work with a copy to avoid modifying the original data\n",
    "\n",
    "#     # Convert categorical variables into numerical using One-Hot Encoding for confounders\n",
    "#     df_encoded = pd.get_dummies(df, columns=confounders, drop_first=True)\n",
    "\n",
    "#     # Define X (features) and y (outcome)\n",
    "#     X = df_encoded.drop(columns=[outcome_col])\n",
    "#     y = df_encoded[outcome_col].astype('category').cat.codes  # Convert outcome to numerical\n",
    "\n",
    "#     # Train/Test Split\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Fit Linear Regression Model\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(X_train, y_train)\n",
    "#     predictions = model.predict(X_test)\n",
    "\n",
    "#     # Evaluate Model\n",
    "#     mae = mean_absolute_error(y_test, predictions)\n",
    "#     console.print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     domain = input(\"Enter the domain (medicine, economics, marketing): \").strip().lower()\n",
    "#     num_samples = int(input(\"Enter the number of samples: \"))\n",
    "#     if domain not in DOMAIN_COLUMNS:\n",
    "#         console.print(\"[bold red]Invalid domain entered![/bold red]\")\n",
    "#         return\n",
    "    \n",
    "#     df = generate_synthetic_data_groq(domain, num_samples)\n",
    "#     if df is None:\n",
    "#         return\n",
    "    \n",
    "#     treatment_col = \"treatment\"\n",
    "#     outcome_col = \"outcome\"\n",
    "#     confounders = [col for col in DOMAIN_COLUMNS[domain] if col not in [treatment_col, outcome_col]]\n",
    "#     identify_causal_relationship(df, treatment_col, outcome_col, confounders)\n",
    "#     console.print(\"[bold green]Analysis complete![/bold green]\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673080a-9678-4eb9-a344-e2905cc11f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# from rich.console import Console\n",
    "\n",
    "# # Initialize the console for rich text output\n",
    "# console = Console()\n",
    "\n",
    "# # Define the columns for each domain\n",
    "# DOMAIN_COLUMNS = {\n",
    "#     \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "#     \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "#     \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"]\n",
    "# }\n",
    "\n",
    "# def generate_synthetic_data_groq(domain, num_samples):\n",
    "#     \"\"\"\n",
    "#     Uses Groq API (LLaMA 3) to generate structured synthetic data.\n",
    "#     \"\"\"\n",
    "#     console.print(f\"[bold yellow]Generating Synthetic Data for {domain.capitalize()} using LLaMA 3...[/bold yellow]\")\n",
    "\n",
    "#     API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "#     API_KEY = \"\"  # Replace with your actual API key\n",
    "\n",
    "#     if domain not in DOMAIN_COLUMNS:\n",
    "#         console.print(\"[bold red]Invalid domain selected! Choose from: medicine, economics, marketing.[/bold red]\")\n",
    "#         return None\n",
    "\n",
    "#     headers = {\n",
    "#         \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "\n",
    "#     prompt = f\"\"\"\n",
    "#     Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain.\n",
    "#     Return ONLY a valid JSON array with no explanations or formatting.\n",
    "#     Schema:\n",
    "#     {json.dumps(DOMAIN_COLUMNS[domain], indent=2)}\n",
    "#     \"\"\"\n",
    "\n",
    "#     payload = {\n",
    "#         \"model\": \"llama3-70b-8192\",\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "#         \"temperature\": 0.7,\n",
    "#         \"max_tokens\": 4000  # Increase token limit to reduce truncation risk\n",
    "#     }\n",
    "\n",
    "#     try:\n",
    "#         response = requests.post(API_URL, json=payload, headers=headers)\n",
    "#         response.raise_for_status()\n",
    "#         data = response.json()\n",
    "\n",
    "#         if \"choices\" not in data or not data[\"choices\"]:\n",
    "#             console.print(\"[bold red]Invalid API response: No choices found.[/bold red]\")\n",
    "#             return None\n",
    "\n",
    "#         raw_text = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "#         console.print(f\"[bold cyan]Raw Model Response (first 500 chars):[/bold cyan] {raw_text[:500]}...\")\n",
    "\n",
    "#         # Extract JSON data from the model response\n",
    "#         json_data = extract_json_from_response(raw_text)\n",
    "#         if json_data:\n",
    "#             df = pd.DataFrame(json_data)\n",
    "#             console.print(df.head())  # Display sample data\n",
    "#             return df\n",
    "#         return None\n",
    "\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         console.print(f\"[bold red]Error fetching data from Groq API: {e}[/bold red]\")\n",
    "\n",
    "# def extract_json_from_response(response_text):\n",
    "#     \"\"\"\n",
    "#     Attempts to extract valid JSON from the API response, handling truncation, formatting issues,\n",
    "#     and boolean values incorrectly represented.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         return json.loads(response_text)  # Direct parsing attempt\n",
    "#     except json.JSONDecodeError:\n",
    "#         console.print(\"[bold yellow]Direct JSON parsing failed. Attempting regex extraction...[/bold yellow]\")\n",
    "\n",
    "#     # Improved regex to capture JSON array from the response\n",
    "#     match = re.search(r\"\\[\\s*\\{.*?\\}\\s*\\]\", response_text, re.DOTALL)\n",
    "#     if match:\n",
    "#         extracted_json = match.group(0).strip()\n",
    "\n",
    "#         # Remove potential truncation artifacts (like ellipses) or extra commas\n",
    "#         extracted_json = re.sub(r\",?\\s*\\.\\.\\.\\s*$\", \"\", extracted_json)\n",
    "\n",
    "#         # Handle missing or extra commas, braces, and brackets\n",
    "#         extracted_json = re.sub(r'(?<=\\})\\s*,\\s*(?=\\{)', '}', extracted_json)  # Fix any misplaced commas between objects\n",
    "#         extracted_json = re.sub(r'(?<=\\])\\s*,\\s*(?=\\})', ']', extracted_json)  # Handle commas before closing brackets\n",
    "\n",
    "#         # Handle boolean values and format them correctly for all domains\n",
    "#         extracted_json = re.sub(r'\"(promotion_active|policy_change)\":\\s*(true|false)', lambda match: f'\"{match.group(1)}\": \"{match.group(2).lower()}\"', extracted_json)\n",
    "\n",
    "#         # Ensure the JSON ends properly if not already\n",
    "#         if not extracted_json.endswith(\"]\"):\n",
    "#             extracted_json += \"]\"\n",
    "#         if not extracted_json.startswith(\"[\"):\n",
    "#             extracted_json = \"[\" + extracted_json\n",
    "\n",
    "#         try:\n",
    "#             parsed_json = json.loads(extracted_json)\n",
    "#             if isinstance(parsed_json, list) and all(isinstance(item, dict) for item in parsed_json):\n",
    "#                 console.print(\"[green]Successfully extracted JSON data![/green]\")\n",
    "#                 return parsed_json\n",
    "#         except json.JSONDecodeError as e:\n",
    "#             console.print(f\"[bold red]Still invalid JSON: {e}[/bold red]\")\n",
    "\n",
    "#     console.print(\"[bold red]Error: Could not extract valid JSON from model response.[/bold red]\")\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def perform_causal_analysis(df, domain):\n",
    "#     \"\"\"\n",
    "#     Example of how you could perform causal analysis (for demonstration).\n",
    "#     This function varies depending on the domain structure.\n",
    "#     \"\"\"\n",
    "#     if domain == \"medicine\":\n",
    "#         # Placeholder for medical causal analysis logic\n",
    "#         console.print(f\"[bold green]Performing causal analysis for medicine domain...[/bold green]\")\n",
    "#         # Implement specific analysis logic for the 'medicine' domain\n",
    "#     elif domain == \"economics\":\n",
    "#         # Placeholder for economics causal analysis logic\n",
    "#         console.print(f\"[bold green]Performing causal analysis for economics domain...[/bold green]\")\n",
    "#         # Implement specific analysis logic for the 'economics' domain\n",
    "#     elif domain == \"marketing\":\n",
    "#         # Placeholder for marketing causal analysis logic\n",
    "#         console.print(f\"[bold green]Performing causal analysis for marketing domain...[/bold green]\")\n",
    "#         # Implement specific analysis logic for the 'marketing' domain\n",
    "\n",
    "\n",
    "# def perform_intervention_analysis(df, domain):\n",
    "#     \"\"\"\n",
    "#     Example of how you could perform intervention analysis (for demonstration).\n",
    "#     This function varies depending on the domain structure.\n",
    "#     \"\"\"\n",
    "#     if domain == \"medicine\":\n",
    "#         # Placeholder for medical intervention analysis logic\n",
    "#         console.print(f\"[bold green]Performing intervention analysis for medicine domain...[/bold green]\")\n",
    "#         # Implement specific analysis logic for the 'medicine' domain\n",
    "#     elif domain == \"economics\":\n",
    "#         # Placeholder for economics intervention analysis logic\n",
    "#         console.print(f\"[bold green]Performing intervention analysis for economics domain...[/bold green]\")\n",
    "#         # Implement specific analysis logic for the 'economics' domain\n",
    "#     elif domain == \"marketing\":\n",
    "#         # Placeholder for marketing intervention analysis logic\n",
    "#         console.print(f\"[bold green]Performing intervention analysis for marketing domain...[/bold green]\")\n",
    "#         # Implement specific analysis logic for the 'marketing' domain\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example of usage\n",
    "#     domain = \"marketing\"  # Choose a domain: \"medicine\", \"economics\", \"marketing\"\n",
    "#     num_samples = 100\n",
    "#     df = generate_synthetic_data_groq(domain, num_samples)\n",
    "#     if df is not None:\n",
    "#         perform_causal_analysis(df, domain)\n",
    "#         perform_intervention_analysis(df, domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6e229-7cf4-449d-aff6-4130a99de689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"]\n",
    "}\n",
    "\n",
    "def generate_synthetic_data_groq(domain, num_samples, api_key):\n",
    "    \"\"\"\n",
    "    Uses Groq API (LLaMA 3) to generate structured synthetic data.\n",
    "    \"\"\"\n",
    "    console.print(f\"[bold yellow]Generating Synthetic Data for {domain.capitalize()} using LLaMA 3...[/bold yellow]\")\n",
    "\n",
    "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        console.print(\"[bold red]Invalid domain selected! Choose from: medicine, economics, marketing.[/bold red]\")\n",
    "        return None\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain.\n",
    "    Return ONLY a valid JSON array with no explanations or formatting.\n",
    "    Schema:\n",
    "    {json.dumps(DOMAIN_COLUMNS[domain], indent=2)}\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 4000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if \"choices\" not in data or not data[\"choices\"]:\n",
    "            console.print(\"[bold red]Invalid API response: No choices found.[/bold red]\")\n",
    "            return None\n",
    "\n",
    "        raw_text = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        console.print(f\"[bold cyan]Raw Model Response (first 500 chars):[/bold cyan] {raw_text[:500]}...\")\n",
    "\n",
    "        json_data = extract_json_from_response(raw_text)\n",
    "        if json_data:\n",
    "            df = pd.DataFrame(json_data)\n",
    "            console.print(df.head())\n",
    "            return df\n",
    "        return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        console.print(f\"[bold red]Error fetching data from Groq API: {e}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Attempts to extract valid JSON from the API response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(response_text)  \n",
    "    except json.JSONDecodeError:\n",
    "        console.print(\"[bold yellow]Direct JSON parsing failed. Attempting regex extraction...[/bold yellow]\")\n",
    "\n",
    "    match = re.search(r\"\\[.*\\]\", response_text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_json = match.group(0).strip()\n",
    "\n",
    "        extracted_json = re.sub(r\",\\s*]\", \"]\", extracted_json)  # Remove trailing commas\n",
    "        extracted_json = extracted_json.replace(\"True\", \"true\").replace(\"False\", \"false\")  # Fix boolean values\n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(extracted_json)\n",
    "            if isinstance(parsed_json, list):\n",
    "                console.print(\"[green]Successfully extracted JSON data![/green]\")\n",
    "                return parsed_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            console.print(f\"[bold red]Still invalid JSON: {e}[/bold red]\")\n",
    "\n",
    "    console.print(\"[bold red]Error: Could not extract valid JSON from model response.[/bold red]\")\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"\" \n",
    "    domain = \"economics\" \n",
    "    num_samples = 100\n",
    "    df = generate_synthetic_data_groq(domain, num_samples, api_key)\n",
    "    if df is not None:\n",
    "        console.print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f18ac3-cbac-4f5c-b74d-475907813485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"]\n",
    "}\n",
    "\n",
    "def generate_synthetic_data_groq(domain, num_samples, api_key):\n",
    "    \"\"\"\n",
    "    Uses Groq API (LLaMA 3) to generate structured synthetic data.\n",
    "    \"\"\"\n",
    "    console.print(f\"[bold yellow]Generating Synthetic Data for {domain.capitalize()} using LLaMA 3...[/bold yellow]\")\n",
    "\n",
    "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        console.print(\"[bold red]Invalid domain selected! Choose from: medicine, economics, marketing.[/bold red]\")\n",
    "        return None\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain.\n",
    "    Return ONLY a valid JSON array with no explanations or formatting.\n",
    "    Schema:\n",
    "    {json.dumps(DOMAIN_COLUMNS[domain], indent=2)}\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 4000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if \"choices\" not in data or not data[\"choices\"]:\n",
    "            console.print(\"[bold red]Invalid API response: No choices found.[/bold red]\")\n",
    "            return None\n",
    "\n",
    "        raw_text = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        console.print(f\"[bold cyan]Raw Model Response (first 500 chars):[/bold cyan] {raw_text[:500]}...\")\n",
    "\n",
    "   \n",
    "        json_data = extract_json_from_response(raw_text)\n",
    "        if json_data:\n",
    "            df = pd.DataFrame(json_data)\n",
    "            console.print(f\"[bold green]Data Collected Successfully![/bold green]\")\n",
    "            console.print(df.head())\n",
    "            return df\n",
    "        return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        console.print(f\"[bold red]Error fetching data from Groq API: {e}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Attempts to extract valid JSON from the API response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(response_text)  \n",
    "    except json.JSONDecodeError:\n",
    "        console.print(\"[bold yellow]Direct JSON parsing failed. Attempting regex extraction...[/bold yellow]\")\n",
    "\n",
    "    # Extract JSON array using regex\n",
    "    match = re.search(r\"\\[.*\\]\", response_text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_json = match.group(0).strip()\n",
    "\n",
    "        # Fix common JSON formatting issues\n",
    "        extracted_json = re.sub(r\",\\s*]\", \"]\", extracted_json)  # Remove trailing commas\n",
    "        extracted_json = extracted_json.replace(\"True\", \"true\").replace(\"False\", \"false\")  # Fix boolean values\n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(extracted_json)\n",
    "            if isinstance(parsed_json, list):\n",
    "                console.print(\"[green]Successfully extracted JSON data![/green]\")\n",
    "                return parsed_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            console.print(f\"[bold red]Still invalid JSON: {e}[/bold red]\")\n",
    "\n",
    "    console.print(\"[bold red]Error: Could not extract valid JSON from model response.[/bold red]\")\n",
    "    return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame by handling missing values and outliers.\n",
    "    \"\"\"\n",
    "\n",
    "    num_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    cat_columns = df.select_dtypes(include=[object]).columns\n",
    "    for col in cat_columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "    for col in num_columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"\"  \n",
    "    domain = \"marketing\" \n",
    "    num_samples = 100\n",
    "    df = generate_synthetic_data_groq(domain, num_samples, api_key)\n",
    "\n",
    "    if df is not None:\n",
    "        df = preprocess_data(df)\n",
    "        console.print(f\"[bold green]Preprocessed Data:[/bold green]\")\n",
    "        console.print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea4600-ebf6-4ed9-a169-e74e59ff81d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich.console import Console\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "console = Console()\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"],\n",
    "    \"finance\": [\"stock_price\", \"interest_rate\", \"market_sentiment\", \"economic_indicator\"]\n",
    "}\n",
    "\n",
    "def generate_synthetic_data_groq(domain, num_samples, api_key):\n",
    "    \"\"\"\n",
    "    Uses Groq API (LLaMA 3) to generate structured synthetic data.\n",
    "    \"\"\"\n",
    "    console.print(f\"[bold yellow]Generating Synthetic Data for {domain.capitalize()} using LLaMA 3...[/bold yellow]\")\n",
    "\n",
    "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        console.print(\"[bold red]Invalid domain selected! Choose from: medicine, economics, marketing, finance.[/bold red]\")\n",
    "        return None\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain.\n",
    "    Return ONLY a valid JSON array with no explanations or formatting.\n",
    "    Schema:\n",
    "    {json.dumps(DOMAIN_COLUMNS[domain], indent=2)}\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 4000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if \"choices\" not in data or not data[\"choices\"]:\n",
    "            console.print(\"[bold red]Invalid API response: No choices found.[/bold red]\")\n",
    "            return None\n",
    "\n",
    "        raw_text = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        console.print(f\"[bold cyan]Raw Model Response (first 500 chars):[/bold cyan] {raw_text[:500]}...\")\n",
    "\n",
    "        # Extract JSON data from the model response\n",
    "        json_data = extract_json_from_response(raw_text)\n",
    "        if json_data:\n",
    "            df = pd.DataFrame(json_data)\n",
    "            console.print(f\"[bold green]Data Collected Successfully![/bold green]\")  # Display first few rows\n",
    "            console.print(df.head())\n",
    "            return df\n",
    "        return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        console.print(f\"[bold red]Error fetching data from Groq API: {e}[/bold red]\")\n",
    "        return None\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Attempts to extract valid JSON from the API response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(response_text) \n",
    "    except json.JSONDecodeError:\n",
    "        console.print(\"[bold yellow]Direct JSON parsing failed. Attempting regex extraction...[/bold yellow]\")\n",
    "\n",
    "    match = re.search(r\"\\[.*\\]\", response_text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_json = match.group(0).strip()\n",
    "\n",
    "        extracted_json = re.sub(r\",\\s*]\", \"]\", extracted_json)  # Remove trailing commas\n",
    "        extracted_json = extracted_json.replace(\"True\", \"true\").replace(\"False\", \"false\")  # Fix boolean values\n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(extracted_json)\n",
    "            if isinstance(parsed_json, list):\n",
    "                console.print(\"[green]Successfully extracted JSON data![/green]\")\n",
    "                return parsed_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            console.print(f\"[bold red]Still invalid JSON: {e}[/bold red]\")\n",
    "\n",
    "    console.print(\"[bold red]Error: Could not extract valid JSON from model response.[/bold red]\")\n",
    "    return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame by handling missing values and outliers.\n",
    "    \"\"\"\n",
    "    num_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    cat_columns = df.select_dtypes(include=[object]).columns\n",
    "    for col in cat_columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "    \n",
    "    for col in num_columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    " \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "  \n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def identify_causal_relationship(df):\n",
    "    \"\"\"\n",
    "    Identifies potential causal relationships between variables using statistical methods and machine learning models.\n",
    "    \"\"\"\n",
    "    target_column = df.columns[-1] \n",
    "\n",
    "    correlation_matrix = df.corr()\n",
    "    console.print(f\"[bold cyan]Correlation Matrix:[/bold cyan]\\n{correlation_matrix}\\n\")\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        \"Feature\": X.columns,\n",
    "        \"Importance\": model.feature_importances_\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    console.print(f\"[bold cyan]Feature Importance (Potential Causal Indicators):[/bold cyan]\\n{feature_importance}\\n\")\n",
    "\n",
    "    return correlation_matrix, feature_importance\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"\" \n",
    "    domain = \"medicine\" \n",
    "    num_samples = 100\n",
    "    df = generate_synthetic_data_groq(domain, num_samples, api_key)\n",
    "\n",
    "    if df is not None:\n",
    "        df = preprocess_data(df)\n",
    "        console.print(f\"[bold green]Preprocessed Data:[/bold green]\")\n",
    "        console.print(df.head())\n",
    "\n",
    "        correlation_matrix, feature_importance = identify_causal_relationship(df)\n",
    "        console.print(f\"[bold green]Causal Relationship Analysis:[/bold green]\")\n",
    "        console.print(f\"[bold yellow]Correlation Matrix:[/bold yellow]\\n{correlation_matrix}\")\n",
    "        console.print(f\"[bold yellow]Feature Importance (Potential Causal Indicators):[/bold yellow]\\n{feature_importance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9389234a-1da9-4493-90b2-1cee47bf53db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich.console import Console\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "console = Console()\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"],\n",
    "    \"finance\": [\"stock_price\", \"interest_rate\", \"market_sentiment\", \"economic_indicator\"]\n",
    "}\n",
    "\n",
    "def generate_synthetic_data_groq(domain, num_samples, api_key):\n",
    "    \"\"\"\n",
    "    Uses Groq API (LLaMA 3) to generate structured synthetic data.\n",
    "    \"\"\"\n",
    "    console.print(f\"[bold yellow]Generating Synthetic Data for {domain.capitalize()} using LLaMA 3...[/bold yellow]\")\n",
    "\n",
    "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        console.print(\"[bold red]Invalid domain selected! Choose from: medicine, economics, marketing, finance.[/bold red]\")\n",
    "        return None\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain.\n",
    "    Return ONLY a valid JSON array with no explanations or formatting.\n",
    "    Schema:\n",
    "    {json.dumps(DOMAIN_COLUMNS[domain], indent=2)}\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 4000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if \"choices\" not in data or not data[\"choices\"]:\n",
    "            console.print(\"[bold red]Invalid API response: No choices found.[/bold red]\")\n",
    "            return None\n",
    "\n",
    "        raw_text = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        console.print(f\"[bold cyan]Raw Model Response (first 500 chars):[/bold cyan] {raw_text[:500]}...\")\n",
    "\n",
    "        json_data = extract_json_from_response(raw_text)\n",
    "        if json_data:\n",
    "            df = pd.DataFrame(json_data)\n",
    "            console.print(f\"[bold green]Data Collected Successfully![/bold green]\")  # Display first few rows\n",
    "            console.print(df.head())\n",
    "            return df\n",
    "        return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        console.print(f\"[bold red]Error fetching data from Groq API: {e}[/bold red]\")\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Attempts to extract valid JSON from the API response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(response_text)  # Direct parsing attempt\n",
    "    except json.JSONDecodeError:\n",
    "        console.print(\"[bold yellow]Direct JSON parsing failed. Attempting regex extraction...[/bold yellow]\")\n",
    "\n",
    "    match = re.search(r\"\\[.*\\]\", response_text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_json = match.group(0).strip()\n",
    "\n",
    "        extracted_json = re.sub(r\",\\s*]\", \"]\", extracted_json)  # Remove trailing commas\n",
    "        extracted_json = extracted_json.replace(\"True\", \"true\").replace(\"False\", \"false\")  # Fix boolean values\n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(extracted_json)\n",
    "            if isinstance(parsed_json, list):\n",
    "                console.print(\"[green]Successfully extracted JSON data![/green]\")\n",
    "                return parsed_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            console.print(f\"[bold red]Still invalid JSON: {e}[/bold red]\")\n",
    "\n",
    "    console.print(\"[bold red]Error: Could not extract valid JSON from model response.[/bold red]\")\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame by handling missing values and outliers.\n",
    "    \"\"\"\n",
    "  \n",
    "    num_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    cat_columns = df.select_dtypes(include=[object]).columns\n",
    "    for col in cat_columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "    for col in num_columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "  \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def identify_causal_relationship(df):\n",
    "    \"\"\"\n",
    "    Identifies potential causal relationships between variables using statistical methods and machine learning models.\n",
    "    \"\"\"\n",
    "\n",
    "    label_encoders = {}\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "    target_column = df.columns[-1] \n",
    "\n",
    "    correlation_matrix = df.corr()\n",
    "    console.print(f\"[bold cyan]Correlation Matrix:[/bold cyan]\\n{correlation_matrix}\\n\")\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        \"Feature\": X.columns,\n",
    "        \"Importance\": model.feature_importances_\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    console.print(f\"[bold cyan]Feature Importance (Potential Causal Indicators):[/bold cyan]\\n{feature_importance}\\n\")\n",
    "\n",
    "    return correlation_matrix, feature_importance\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"\" \n",
    "    domain = \"medicine\"  \n",
    "    num_samples = 100  \n",
    "\n",
    "    df = generate_synthetic_data_groq(domain, num_samples, api_key)\n",
    "    if df is not None:\n",
    "        df = preprocess_data(df)\n",
    "        console.print(f\"[bold green]Preprocessed Data:[/bold green]\\n{df.head()}\")\n",
    "\n",
    "        correlation_matrix, feature_importance = identify_causal_relationship(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e5cc3-28c6-4908-92aa-1649b2b41110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich.console import Console\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "console = Console()\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"],\n",
    "    \"finance\": [\"stock_price\", \"interest_rate\", \"market_sentiment\", \"economic_indicator\"]\n",
    "}\n",
    "\n",
    "def generate_synthetic_data_groq(domain, num_samples, api_key):\n",
    "    \"\"\"\n",
    "    Uses Groq API (LLaMA 3) to generate structured synthetic data.\n",
    "    \"\"\"\n",
    "    console.print(f\"[bold yellow]Generating Synthetic Data for {domain.capitalize()} using LLaMA 3...[/bold yellow]\")\n",
    "\n",
    "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        console.print(\"[bold red]Invalid domain selected! Choose from: medicine, economics, marketing, finance.[/bold red]\")\n",
    "        return None\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain.\n",
    "    Return ONLY a valid JSON array with no explanations or formatting.\n",
    "    Schema:\n",
    "    {json.dumps(DOMAIN_COLUMNS[domain], indent=2)}\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 4000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if \"choices\" not in data or not data[\"choices\"]:\n",
    "            console.print(\"[bold red]Invalid API response: No choices found.[/bold red]\")\n",
    "            return None\n",
    "\n",
    "        raw_text = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        console.print(f\"[bold cyan]Raw Model Response (first 500 chars):[/bold cyan] {raw_text[:500]}...\")\n",
    "\n",
    "        json_data = extract_json_from_response(raw_text)\n",
    "        if json_data:\n",
    "            df = pd.DataFrame(json_data)\n",
    "            console.print(f\"[bold green]Data Collected Successfully![/bold green]\")  \n",
    "            console.print(df.head())\n",
    "            return df\n",
    "        return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        console.print(f\"[bold red]Error fetching data from Groq API: {e}[/bold red]\")\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Attempts to extract valid JSON from the API response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(response_text)  \n",
    "    except json.JSONDecodeError:\n",
    "        console.print(\"[bold yellow]Direct JSON parsing failed. Attempting regex extraction...[/bold yellow]\")\n",
    "\n",
    "    match = re.search(r\"\\[.*\\]\", response_text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_json = match.group(0).strip()\n",
    "\n",
    "        extracted_json = re.sub(r\",\\s*]\", \"]\", extracted_json) \n",
    "        extracted_json = extracted_json.replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(extracted_json)\n",
    "            if isinstance(parsed_json, list):\n",
    "                console.print(\"[green]Successfully extracted JSON data![/green]\")\n",
    "                return parsed_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            console.print(f\"[bold red]Still invalid JSON: {e}[/bold red]\")\n",
    "\n",
    "    console.print(\"[bold red]Error: Could not extract valid JSON from model response.[/bold red]\")\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame by handling missing values and outliers.\n",
    "    \"\"\"\n",
    "\n",
    "    num_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    cat_columns = df.select_dtypes(include=[object]).columns\n",
    "    for col in cat_columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "    for col in num_columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def identify_causal_relationship(df):\n",
    "    \"\"\"\n",
    "    Identifies potential causal relationships between variables using statistical methods and machine learning models.\n",
    "    \"\"\"\n",
    "  \n",
    "    label_encoders = {}\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "    target_column = df.columns[-1]\n",
    "\n",
    "    correlation_matrix = df.corr()\n",
    "    console.print(f\"[bold cyan]Correlation Matrix:[/bold cyan]\\n{correlation_matrix}\\n\")\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        \"Feature\": X.columns,\n",
    "        \"Importance\": model.feature_importances_\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    console.print(f\"[bold cyan]Feature Importance (Potential Causal Indicators):[/bold cyan]\\n{feature_importance}\\n\")\n",
    "\n",
    "    return correlation_matrix, feature_importance\n",
    "\n",
    "def intervention_analysis(df, target_column, intervention_column, intervention_value):\n",
    "    \"\"\"\n",
    "    Simulate \"what-if\" scenarios to estimate the causal impact of actions.\n",
    "    \"\"\"\n",
    "  \n",
    "    df_copy = df.copy()\n",
    "    df_copy[intervention_column] = intervention_value\n",
    "\n",
    "  \n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    original_prediction = model.predict(X)\n",
    "    intervention_prediction = model.predict(df_copy.drop(columns=[target_column]))\n",
    "\n",
    "    impact = np.mean(intervention_prediction - original_prediction)\n",
    "    \n",
    "    console.print(f\"[bold cyan]Intervention Analysis Impact:[/bold cyan] The intervention in {intervention_column} by setting it to {intervention_value} resulted in an average impact of {impact:.2f} on the target variable.\")\n",
    "\n",
    "    return impact\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"\"  \n",
    "    domain = \"economics\"\n",
    "    num_samples = 100  \n",
    "\n",
    "    df = generate_synthetic_data_groq(domain, num_samples, api_key)\n",
    "    if df is not None:\n",
    "        df = preprocess_data(df)\n",
    "        console.print(f\"[bold green]Preprocessed Data:[/bold green]\\n{df.head()}\")\n",
    "\n",
    "        correlation_matrix, feature_importance = identify_causal_relationship(df)\n",
    "\n",
    "        if domain == \"medicine\":\n",
    "            target_column = \"outcome\" \n",
    "            intervention_column = \"treatment\"  \n",
    "            intervention_value = 10 \n",
    "            \n",
    "            impact = intervention_analysis(df, target_column, intervention_column, intervention_value)\n",
    "            console.print(f\"[bold cyan]Impact of intervention on {target_column} due to change in {intervention_column}: {impact}[/bold cyan]\")\n",
    "\n",
    "  \n",
    "        elif domain == \"economics\":\n",
    "            target_column = \"economic_growth\"  \n",
    "            intervention_column = \"income\"\n",
    "            intervention_value = 5 \n",
    "            \n",
    "            impact = intervention_analysis(df, target_column, intervention_column, intervention_value)\n",
    "            console.print(f\"[bold cyan]Impact of intervention on {target_column} due to change in {intervention_column}: {impact}[/bold cyan]\")\n",
    "\n",
    "        elif domain == \"marketing\":\n",
    "            target_column = \"sales\" \n",
    "            intervention_column = \"ad_spend\" \n",
    "            intervention_value = 50000  \n",
    "\n",
    "            impact = intervention_analysis(df, target_column, intervention_column, intervention_value)\n",
    "            console.print(f\"[bold cyan]Impact of intervention on {target_column} due to change in {intervention_column}: {impact}[/bold cyan]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb9c65-dd5e-4bfa-b9af-b0f7e0da20bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich.console import Console\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "console = Console()\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"],\n",
    "    \"finance\": [\"stock_price\", \"interest_rate\", \"market_sentiment\", \"economic_indicator\"]\n",
    "   \n",
    "}\n",
    "\n",
    "def generate_synthetic_data_groq(domain, num_samples, api_key):\n",
    "    \"\"\"\n",
    "    Uses Groq API (LLaMA 3) to generate structured synthetic data.\n",
    "    \"\"\"\n",
    "    console.print(f\"[bold yellow]Generating Synthetic Data for {domain.capitalize()} using LLaMA 3...[/bold yellow]\")\n",
    "\n",
    "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        console.print(\"[bold red]Invalid domain selected! Choose from: medicine, economics, marketing, finance.[/bold red]\")\n",
    "        return None\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain.\n",
    "    Return ONLY a valid JSON array with no explanations or formatting.\n",
    "    Schema:\n",
    "    {json.dumps(DOMAIN_COLUMNS[domain], indent=2)}\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 4000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if \"choices\" not in data or not data[\"choices\"]:\n",
    "            console.print(\"[bold red]Invalid API response: No choices found.[/bold red]\")\n",
    "            return None\n",
    "\n",
    "        raw_text = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        console.print(f\"[bold cyan]Raw Model Response (first 500 chars):[/bold cyan] {raw_text[:500]}...\")\n",
    "\n",
    "        # Extract JSON data from the model response\n",
    "        json_data = extract_json_from_response(raw_text)\n",
    "        if json_data:\n",
    "            df = pd.DataFrame(json_data)\n",
    "            console.print(f\"[bold green]Data Collected Successfully![/bold green]\")  # Display first few rows\n",
    "            console.print(df.head())\n",
    "            return df\n",
    "        return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        console.print(f\"[bold red]Error fetching data from Groq API: {e}[/bold red]\")\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Attempts to extract valid JSON from the API response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        console.print(\"[bold yellow]Direct JSON parsing failed. Attempting regex extraction...[/bold yellow]\")\n",
    "\n",
    "    match = re.search(r\"\\[.*\\]\", response_text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_json = match.group(0).strip()\n",
    "\n",
    "        extracted_json = re.sub(r\",\\s*]\", \"]\", extracted_json)\n",
    "        extracted_json = extracted_json.replace(\"True\", \"true\").replace(\"False\", \"false\") \n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(extracted_json)\n",
    "            if isinstance(parsed_json, list):\n",
    "                console.print(\"[green]Successfully extracted JSON data![/green]\")\n",
    "                return parsed_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            console.print(f\"[bold red]Still invalid JSON: {e}[/bold red]\")\n",
    "\n",
    "    console.print(\"[bold red]Error: Could not extract valid JSON from model response.[/bold red]\")\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame by handling missing values and outliers.\n",
    "    \"\"\"\n",
    "    num_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    cat_columns = df.select_dtypes(include=[object]).columns\n",
    "    for col in cat_columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "    for col in num_columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def identify_causal_relationship(df):\n",
    "    \"\"\"\n",
    "    Identifies potential causal relationships between variables using statistical methods and machine learning models.\n",
    "    \"\"\"\n",
    "    label_encoders = {}\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "    target_column = df.columns[-1] \n",
    "\n",
    "    correlation_matrix = df.corr()\n",
    "    console.print(f\"[bold cyan]Correlation Matrix:[/bold cyan]\\n{correlation_matrix}\\n\")\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        \"Feature\": X.columns,\n",
    "        \"Importance\": model.feature_importances_\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    console.print(f\"[bold cyan]Feature Importance (Potential Causal Indicators):[/bold cyan]\\n{feature_importance}\\n\")\n",
    "\n",
    "    return correlation_matrix, feature_importance\n",
    "\n",
    "def intervention_analysis(df, target_column, intervention_column, intervention_value):\n",
    "    \"\"\"\n",
    "    Simulate \"what-if\" scenarios to estimate the causal impact of actions.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy[intervention_column] = intervention_value\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    original_prediction = model.predict(X)\n",
    "    intervention_prediction = model.predict(df_copy.drop(columns=[target_column]))\n",
    "\n",
    "    impact = np.mean(intervention_prediction - original_prediction)\n",
    "    \n",
    "    console.print(f\"[bold cyan]Intervention Analysis Impact:[/bold cyan] The intervention in {intervention_column} by setting it to {intervention_value} resulted in an average impact of {impact:.2f} on the target variable.\")\n",
    "\n",
    "    return impact\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"\"  \n",
    "    domain = \"marketing\" \n",
    "    num_samples = 100  \n",
    "\n",
    "    df = generate_synthetic_data_groq(domain, num_samples, api_key)\n",
    "    if df is not None:\n",
    "        df = preprocess_data(df)\n",
    "        console.print(f\"[bold green]Preprocessed Data:[/bold green]\\n{df.head()}\")\n",
    "\n",
    "        correlation_matrix, feature_importance = identify_causal_relationship(df)\n",
    "\n",
    "        if domain == \"medicine\":\n",
    "            target_column = \"outcome\"  \n",
    "            intervention_column = \"age\"  \n",
    "            intervention_value = 45  \n",
    "            impact = intervention_analysis(df, target_column, intervention_column, intervention_value)\n",
    "            console.print(f\"[bold cyan]Impact of intervention on {target_column} due to change in {intervention_column}: {impact}[/bold cyan]\")\n",
    "\n",
    "        elif domain == \"economics\":\n",
    "            target_column = \"economic_growth\"  \n",
    "            intervention_column = \"income\" \n",
    "            intervention_value = 5 \n",
    "\n",
    "            impact = intervention_analysis(df, target_column, intervention_column, intervention_value)\n",
    "            console.print(f\"[bold cyan]Impact of intervention on {target_column} due to change in {intervention_column}: {impact}[/bold cyan]\")\n",
    "\n",
    "        elif domain == \"marketing\":\n",
    "            target_column = \"sales\" \n",
    "            intervention_column = \"ad_spend\" \n",
    "            intervention_value = 50000  \n",
    "\n",
    "            impact = intervention_analysis(df, target_column, intervention_column, intervention_value)\n",
    "            console.print(f\"[bold cyan]Impact of intervention on {target_column} due to change in {intervention_column}: {impact}[/bold cyan]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba7832-708f-43e6-905b-3ba78f38e891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich.console import Console\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import t\n",
    "\n",
    "console = Console()\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"],\n",
    "    \"finance\": [\"stock_price\", \"interest_rate\", \"market_sentiment\", \"economic_indicator\"]\n",
    "}\n",
    "\n",
    "def generate_synthetic_data_groq(domain, num_samples, api_key):\n",
    "    \"\"\"\n",
    "    Uses Groq API (LLaMA 3) to generate structured synthetic data.\n",
    "    \"\"\"\n",
    "    console.print(f\"[bold yellow]Generating Synthetic Data for {domain.capitalize()} using LLaMA 3...[/bold yellow]\")\n",
    "\n",
    "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        console.print(\"[bold red]Invalid domain selected! Choose from: medicine, economics, marketing, finance.[/bold red]\")\n",
    "        return None\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain.\n",
    "    Return ONLY a valid JSON array with no explanations or formatting.\n",
    "    Schema:\n",
    "    {json.dumps(DOMAIN_COLUMNS[domain], indent=2)}\n",
    "    \"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 4000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if \"choices\" not in data or not data[\"choices\"]:\n",
    "            console.print(\"[bold red]Invalid API response: No choices found.[/bold red]\")\n",
    "            return None\n",
    "\n",
    "        raw_text = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        console.print(f\"[bold cyan]Raw Model Response (first 500 chars):[/bold cyan] {raw_text[:500]}...\")\n",
    "\n",
    "        # Extract JSON data from the model response\n",
    "        json_data = extract_json_from_response(raw_text)\n",
    "        if json_data:\n",
    "            df = pd.DataFrame(json_data)\n",
    "            console.print(f\"[bold green]Data Collected Successfully![/bold green]\")\n",
    "            console.print(df.head())\n",
    "            return df\n",
    "        return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        console.print(f\"[bold red]Error fetching data from Groq API: {e}[/bold red]\")\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"\n",
    "    Attempts to extract valid JSON from the API response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return json.loads(response_text)  # Direct parsing attempt\n",
    "    except json.JSONDecodeError:\n",
    "        console.print(\"[bold yellow]Direct JSON parsing failed. Attempting regex extraction...[/bold yellow]\")\n",
    "\n",
    "    match = re.search(r\"\\[.*\\]\", response_text, re.DOTALL)\n",
    "    if match:\n",
    "        extracted_json = match.group(0).strip()\n",
    "        extracted_json = re.sub(r\",\\s*]\", \"]\", extracted_json)  # Remove trailing commas\n",
    "        extracted_json = extracted_json.replace(\"True\", \"true\").replace(\"False\", \"false\")  # Fix boolean values\n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(extracted_json)\n",
    "            if isinstance(parsed_json, list):\n",
    "                console.print(\"[green]Successfully extracted JSON data![/green]\")\n",
    "                return parsed_json\n",
    "        except json.JSONDecodeError as e:\n",
    "            console.print(f\"[bold red]Still invalid JSON: {e}[/bold red]\")\n",
    "\n",
    "    console.print(\"[bold red]Error: Could not extract valid JSON from model response.[/bold red]\")\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame by handling missing values and outliers.\n",
    "    \"\"\"\n",
    "    num_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    cat_columns = df.select_dtypes(include=[object]).columns\n",
    "    for col in cat_columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "    # Handle outliers using IQR method\n",
    "    for col in num_columns:\n",
    "        Q1, Q3 = df[col].quantile([0.25, 0.75])\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "    return df\n",
    "\n",
    "def identify_causal_relationship(df):\n",
    "    \"\"\"\n",
    "    Identifies potential causal relationships between variables using statistical methods and ML models.\n",
    "    \"\"\"\n",
    "    label_encoders = {}\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "        label_encoders[col] = label_encoder\n",
    "\n",
    "    target_column = df.columns[-1]  \n",
    "    correlation_matrix = df.corr()\n",
    "    console.print(f\"[bold cyan]Correlation Matrix:[/bold cyan]\\n{correlation_matrix}\\n\")\n",
    "\n",
    "    X, y = df.drop(columns=[target_column]), df[target_column]\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        \"Feature\": X.columns,\n",
    "        \"Importance\": model.feature_importances_\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    console.print(f\"[bold cyan]Feature Importance (Potential Causal Indicators):[/bold cyan]\\n{feature_importance}\\n\")\n",
    "\n",
    "    return correlation_matrix, feature_importance\n",
    "\n",
    "def intervention_analysis(df, target_column, intervention_column, intervention_value):\n",
    "    \"\"\"\n",
    "    Simulate \"what-if\" scenarios with confidence intervals for impact estimation.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy[intervention_column] = intervention_value\n",
    "\n",
    "    X, y = df.drop(columns=[target_column]), df[target_column]\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    original_pred = model.predict(X)\n",
    "    intervention_pred = model.predict(df_copy.drop(columns=[target_column]))\n",
    "\n",
    "    impact = np.mean(intervention_pred - original_pred)\n",
    "\n",
    "    std_err = np.std(intervention_pred - original_pred) / np.sqrt(len(y))\n",
    "    confidence = 0.95\n",
    "    t_value = t.ppf((1 + confidence) / 2, df=len(y) - 1)\n",
    "    margin_error = t_value * std_err\n",
    "    lower_bound, upper_bound = impact - margin_error, impact + margin_error\n",
    "\n",
    "    console.print(f\"[bold cyan]Intervention Analysis:[/bold cyan]\")\n",
    "    console.print(f\" - Intervention in {intervention_column}  {intervention_value}\")\n",
    "    console.print(f\" - Predicted impact on {target_column}: {impact:.2f}\")\n",
    "    console.print(f\" - 95% Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n",
    "\n",
    "    return impact, (lower_bound, upper_bound)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"\"\n",
    "    domain = \"marketing\"\n",
    "    num_samples = 100\n",
    "\n",
    "    df = generate_synthetic_data_groq(domain, num_samples, api_key)\n",
    "    if df is not None:\n",
    "        df = preprocess_data(df)\n",
    "        correlation_matrix, feature_importance = identify_causal_relationship(df)\n",
    "        impact, confidence_interval = intervention_analysis(df, \"sales\", \"ad_spend\", 50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc842ed-830b-42a5-9ece-bedbc40c17f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich.console import Console\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import t\n",
    "\n",
    "console = Console()\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"],\n",
    "    \"finance\": [\"stock_price\", \"interest_rate\", \"market_sentiment\", \"economic_indicator\"]\n",
    "}\n",
    "\n",
    "def generate_synthetic_data(api_key, domain, num_samples):\n",
    "    console.print(f\"[bold yellow]Step 1: Data Collection and Preprocessing[/bold yellow]\")\n",
    "    console.print(f\"- Collecting synthetic data for {domain.capitalize()} domain...\")\n",
    "\n",
    "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        console.print(\"[bold red]Invalid domain. Choose from: medicine, economics, marketing, finance.[/bold red]\")\n",
    "        return None\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"\"\"\n",
    "    Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain.\n",
    "    Return ONLY a valid JSON array.\n",
    "    Schema: {json.dumps(DOMAIN_COLUMNS[domain], indent=2)}\n",
    "    \"\"\"\n",
    "    \n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": 0.7, \"max_tokens\": 4000}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        json_data = extract_json_from_response(data[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "\n",
    "        if json_data:\n",
    "            console.print(\"- Successfully generated synthetic data.\")\n",
    "            return pd.DataFrame(json_data)\n",
    "        else:\n",
    "            console.print(\"[bold red]- Data generation failed.[/bold red]\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        console.print(f\"[bold red]- API error: {e}[/bold red]\")\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        match = re.search(r\"\\[.*\\]\", response_text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(0).strip())\n",
    "            except json.JSONDecodeError as e:\n",
    "                console.print(f\"[bold red]JSON extraction failed: {e}[/bold red]\")\n",
    "\n",
    "def preprocess_data(df):\n",
    "    console.print(\"- Handling missing values and encoding categorical variables.\")\n",
    "    df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    console.print(\"- Data preprocessing completed.\")\n",
    "    return df\n",
    "\n",
    "def causal_analysis(df, target):\n",
    "    console.print(f\"\\n[bold cyan]Step 2: Causal Relationship Identification[/bold cyan]\")\n",
    "    console.print(f\"- Identifying key predictors of {target}...\")\n",
    "\n",
    "    X, y = df.drop(columns=[target]), df[target]\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    feature_importance = pd.DataFrame({\"Feature\": X.columns, \"Importance\": model.feature_importances_}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    console.print(f\"- Identified top influential features:\\n{feature_importance.to_string(index=False)}\")\n",
    "    return feature_importance\n",
    "\n",
    "def intervention_analysis(df, target, intervention_col, intervention_value):\n",
    "    console.print(f\"\\n[bold cyan]Step 3: Intervention Analysis[/bold cyan]\")\n",
    "    console.print(f\"- Simulating intervention: Changing {intervention_col} to {intervention_value}...\")\n",
    "\n",
    "    X, y = df.drop(columns=[target]), df[target]\n",
    "    model = LinearRegression().fit(X, y)\n",
    "\n",
    "    original_pred = model.predict(X)\n",
    "    df_copy = df.copy()\n",
    "    df_copy[intervention_col] = intervention_value\n",
    "    new_pred = model.predict(df_copy.drop(columns=[target]))\n",
    "\n",
    "    impact = np.mean(new_pred - original_pred)\n",
    "    std_err = np.std(new_pred - original_pred) / np.sqrt(len(y))\n",
    "    margin_error = t.ppf(0.975, df=len(y)-1) * std_err\n",
    "\n",
    "    console.print(\"- Predicted impact computed.\")\n",
    "    \n",
    "    console.print(f\"\\n[bold green]Step 4: Result Synthesis[/bold green]\")\n",
    "    console.print(f\"- Causal Impact: Changing {intervention_col} to {intervention_value} is predicted to change {target} by {impact:.2f} units.\")\n",
    "    console.print(f\"- Confidence Interval: The effect is statistically significant with a 95% confidence interval of [{impact - margin_error:.2f}, {impact + margin_error:.2f}].\")\n",
    "    \n",
    "    return impact, (impact - margin_error, impact + margin_error)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"\"\n",
    "    domain = input(\"Enter domain (medicine, economics, marketing, finance): \")\n",
    "    target = input(\"Enter target variable from domain: \")\n",
    "    intervention_col = input(\"Enter intervention variable from domain: \")\n",
    "    intervention_value = float(input(\"Enter intervention value: \"))\n",
    "\n",
    "    df = generate_synthetic_data(api_key, domain, 100)\n",
    "    if df is not None:\n",
    "        df = preprocess_data(df)\n",
    "        causal_analysis(df, target)\n",
    "        intervention_analysis(df, target, intervention_col, intervention_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2605686-c88b-4f56-a941-07cf810af34d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"],\n",
    "    \"finance\": [\"stock_price\", \"interest_rate\", \"market_sentiment\", \"economic_indicator\"]\n",
    "}\n",
    "\n",
    "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "def generate_synthetic_data(api_key, domain, num_samples):\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        return None\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain. Return ONLY a valid JSON array.\"\n",
    "    \n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": 0.7, \"max_tokens\": 4000}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(extract_json_from_response(data[\"choices\"][0][\"message\"][\"content\"].strip()))\n",
    "        return enforce_column_consistency(df, domain)\n",
    "    except requests.exceptions.RequestException:\n",
    "        return None\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        match = re.search(r\"\\[.*\\]\", response_text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(0).strip())\n",
    "            except json.JSONDecodeError:\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "def enforce_column_consistency(df, domain):\n",
    "    expected_columns = DOMAIN_COLUMNS[domain]\n",
    "    for col in expected_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan  \n",
    "    df = df[expected_columns]\n",
    "    \n",
    "    for col in expected_columns[:2]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    for col in expected_columns[2:]:\n",
    "        df[col] = df[col].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        if not df[col].mode().empty:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"Unknown\")  # Fallback for empty mode\n",
    "    return df\n",
    "\n",
    "def causal_analysis(api_key, domain, num_samples, target):\n",
    "    df = generate_synthetic_data(api_key, domain, num_samples)\n",
    "    if df is None:\n",
    "        return \"Failed to generate data.\"\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Analyze the causal impact of {target} using the dataset from the {domain} domain. Provide key causal relationships, estimated effects, and limitations.\"\n",
    "    \n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": 0.7, \"max_tokens\": 1000}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"\"\n",
    "\n",
    "def intervention_analysis(api_key, domain, num_samples, target, intervention_col, intervention_value):\n",
    "    df = generate_synthetic_data(api_key, domain, num_samples)\n",
    "    if df is None:\n",
    "        return \"Failed to generate data.\"\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Assess the impact of changing {intervention_col} to {intervention_value} on {target} in the {domain} domain. Provide estimated causal effects and key insights.\"\n",
    "    \n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": 0.7, \"max_tokens\": 1000}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"\"\n",
    "    domain = input(\"Enter domain (medicine, economics, marketing, finance): \")\n",
    "    target = input(\"Enter target variable from domain: \")\n",
    "    intervention_col = input(\"Enter intervention variable from domain: \")\n",
    "    intervention_value = float(input(\"Enter intervention value: \"))\n",
    "    \n",
    "    causal_results = causal_analysis(api_key, domain, 100, target)\n",
    "    intervention_results = intervention_analysis(api_key, domain, 100, target, intervention_col, intervention_value)\n",
    "    \n",
    "    synthesis = f\"\"\"\n",
    "    === Causal Analysis & Intervention Summary ===\n",
    "    \n",
    "    **Domain:** {domain.capitalize()}\n",
    "    **Target Variable:** {target}\n",
    "    **Intervention:** Changing {intervention_col} to {intervention_value}\n",
    "    \n",
    "    **Causal Analysis Findings:**\n",
    "    {causal_results}\n",
    "\n",
    "    **Estimated Intervention Effects:**\n",
    "    {intervention_results}\n",
    "    \n",
    "    **Key Insights & Recommendations:**\n",
    "    - The causal analysis suggests {target} is influenced by {intervention_col} and other factors.\n",
    "    - The intervention analysis estimates the direct impact of modifying {intervention_col}.\n",
    "    - Policymakers or decision-makers should consider these findings before implementing changes.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(synthesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf7333-d868-4df3-8927-c5f036df0764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"],\n",
    "    \"finance\": [\"stock_price\", \"interest_rate\", \"market_sentiment\", \"economic_indicator\"]\n",
    "}\n",
    "\n",
    "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "def generate_synthetic_data(api_key, domain, num_samples):\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        return None\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Generate {num_samples} rows of structured synthetic data in JSON format for the {domain} domain. Return ONLY a valid JSON array.\"\n",
    "    \n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": 0.7, \"max_tokens\": 4000}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(extract_json_from_response(data[\"choices\"][0][\"message\"][\"content\"].strip()))\n",
    "        print(df,\"df\")\n",
    "        return enforce_column_consistency(df, domain)\n",
    "    except requests.exceptions.RequestException:\n",
    "        return None\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        match = re.search(r\"\\[.*\\]\", response_text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(0).strip())\n",
    "            except json.JSONDecodeError:\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "def enforce_column_consistency(df, domain):\n",
    "    expected_columns = DOMAIN_COLUMNS[domain]\n",
    "    for col in expected_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan  \n",
    "    df = df[expected_columns]\n",
    "    \n",
    "    for col in expected_columns[:2]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    for col in expected_columns[2:]:\n",
    "        df[col] = df[col].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        if not df[col].mode().empty:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"Unknown\") \n",
    "    return df\n",
    "\n",
    "def compute_confidence_interval(effect_estimates, confidence=0.95):\n",
    "    mean_effect = np.mean(effect_estimates)\n",
    "    std_error = np.std(effect_estimates, ddof=1) / np.sqrt(len(effect_estimates))\n",
    "    ci_range = t.ppf((1 + confidence) / 2, len(effect_estimates) - 1) * std_error\n",
    "    return mean_effect, (mean_effect - ci_range, mean_effect + ci_range)\n",
    "\n",
    "def causal_analysis(api_key, domain, num_samples, target):\n",
    "    df = generate_synthetic_data(api_key, domain, num_samples)\n",
    "    if df is None:\n",
    "        return \"Failed to generate data.\"\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Analyze the causal impact of {target} using the dataset from the {domain} domain. Provide key causal relationships, estimated effects, and limitations.\"\n",
    "    \n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": 0.7, \"max_tokens\": 1000}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"\"\n",
    "\n",
    "def intervention_analysis(api_key, domain, num_samples, target, intervention_col, intervention_value):\n",
    "    df = generate_synthetic_data(api_key, domain, num_samples)\n",
    "    if df is None:\n",
    "        return \"Failed to generate data.\"\n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Assess the impact of changing {intervention_col} to {intervention_value} on {target} in the {domain} domain. Provide estimated causal effects and key insights.\"\n",
    "    \n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": 0.7, \"max_tokens\": 1000}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"\"\n",
    "    domain = input(\"Enter domain (medicine, economics, marketing, finance): \")\n",
    "    target = input(\"Enter target variable from domain: \")\n",
    "    intervention_col = input(\"Enter intervention variable from domain: \")\n",
    "    intervention_value = float(input(\"Enter intervention value: \"))\n",
    "    \n",
    "    causal_results = causal_analysis(api_key, domain, 100, target)\n",
    "    intervention_results = intervention_analysis(api_key, domain, 100, target, intervention_col, intervention_value)\n",
    "    \n",
    "    mean_effect, confidence_interval = compute_confidence_interval([float(intervention_value)])\n",
    "    \n",
    "    synthesis = f\"\"\"\n",
    "    === Causal Analysis & Intervention Summary ===\n",
    "    \n",
    "    **Domain:** {domain.capitalize()}\n",
    "    **Target Variable:** {target}\n",
    "    **Intervention:** Changing {intervention_col} to {intervention_value}\n",
    "    \n",
    "    **Causal Impact:** {causal_results}\n",
    "    **Confidence Interval:** 95% CI: [{confidence_interval[0]:.2f}, {confidence_interval[1]:.2f}]\n",
    "    **Recommendation:** Based on the analysis, consider implementing {intervention_col} modifications for better outcomes.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(synthesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdaa3f5-e2c4-4523-8b6f-61319e823eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"],\n",
    "    \"finance\": [\"stock_price\", \"interest_rate\", \"market_sentiment\", \"economic_indicator\"]\n",
    "}\n",
    "\n",
    "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "def generate_synthetic_data(api_key, num_samples, domain=\"medicine\"):\n",
    "    \"\"\"Generates synthetic data using the Groq API for a specified domain.\"\"\"\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        raise ValueError(f\"Unsupported domain: {domain}. Choose from {list(DOMAIN_COLUMNS.keys())}.\")\n",
    "\n",
    "    schema = DOMAIN_COLUMNS[domain]\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Generate {num_samples} rows of structured synthetic data in JSON format with the following columns: {', '.join(schema)}. Return ONLY a valid JSON array. Ensure no missing values.\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 2000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        raw_data = response.json()\n",
    "\n",
    "        # Extract JSON\n",
    "        json_data = extract_json_from_response(raw_data[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "        if not json_data:\n",
    "            raise ValueError(\"Failed to extract valid JSON from response.\")\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(json_data)\n",
    "        df = preprocess_data(df)\n",
    "        return df\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching synthetic data: {e}\")\n",
    "        return None\n",
    "    except ValueError as ve:\n",
    "        print(f\"Data extraction error: {ve}\")\n",
    "        return None\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"Extracts valid JSON array from API response.\"\"\"\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        match = re.search(r'\\[.*?\\]', response_text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(0))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON extraction failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Handles missing values and encodes categorical variables.\"\"\"\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else \"Unknown\")\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "def causal_analysis(api_key, df, target):\n",
    "    \"\"\"Performs causal analysis using LLM API.\"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Analyze the causal impact of {target} using the dataset: {df.to_json(orient='records')} Provide key causal relationships, estimated effects, and limitations.\"\n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": 0.7, \"max_tokens\": 1000}\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"Error in causal analysis.\"\n",
    "\n",
    "def intervention_analysis(api_key, df, target, intervention_col, intervention_value):\n",
    "    \"\"\"Performs intervention analysis to assess variable impact using Groq.\"\"\"\n",
    "    df_intervened = df.copy()\n",
    "    df_intervened[intervention_col] = intervention_value  \n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": f\"Assess the impact of changing {intervention_col} to {intervention_value} on {target} using the dataset: {df_intervened.to_json(orient='records')} Provide estimated causal effects and key insights.\"}], \"temperature\": 0.7, \"max_tokens\": 1000}\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers={\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"})\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"Error in intervention analysis.\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run synthetic data generation and analysis.\"\"\"\n",
    "    api_key = \"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\"\n",
    "    domain = \"medicine\"\n",
    "    num_samples = int(input(\"Enter number of samples: \"))\n",
    "    df = generate_synthetic_data(api_key, num_samples, domain)\n",
    "    if df is not None:\n",
    "        print(df.head())\n",
    "        analysis_type = input(\"Select analysis type: 'causal' or 'intervention': \")\n",
    "        target = input(\"Enter target variable: \")\n",
    "        shared_df = df.copy()  # Use same dataset for both analyses\n",
    "        if analysis_type == 'causal':\n",
    "            print(causal_analysis(api_key, shared_df, target))\n",
    "        elif analysis_type == 'intervention':\n",
    "            intervention_col = input(\"Enter intervention column: \")\n",
    "            intervention_value = input(\"Enter intervention value: \")\n",
    "            print(intervention_analysis(api_key, shared_df, target, intervention_col, intervention_value))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273377f9-ee36-42fa-8a85-ceaac2cfbec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\"age\", \"pre_existing_condition\", \"treatment\", \"outcome\"],\n",
    "    \"economics\": [\"income\", \"education_level\", \"policy_change\", \"economic_growth\"],\n",
    "    \"marketing\": [\"ad_spend\", \"promotion_active\", \"customer_satisfaction\", \"sales\"],\n",
    "    \"finance\": [\"stock_price\", \"interest_rate\", \"market_sentiment\", \"economic_indicator\"]\n",
    "}\n",
    "\n",
    "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "def generate_synthetic_data(api_key, num_samples, domain=\"medicine\"):\n",
    "    \"\"\"Generates synthetic data using the Groq API for a specified domain.\"\"\"\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        raise ValueError(f\"Unsupported domain: {domain}. Choose from {list(DOMAIN_COLUMNS.keys())}.\")\n",
    "\n",
    "    schema = DOMAIN_COLUMNS[domain]\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Generate {num_samples} rows of structured synthetic data in JSON format with the following columns: {', '.join(schema)}. Return ONLY a valid JSON array. Ensure no missing values.\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 2000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        raw_data = response.json()\n",
    "\n",
    "        json_data = extract_json_from_response(raw_data[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "        if not json_data:\n",
    "            raise ValueError(\"Failed to extract valid JSON from response.\")\n",
    "\n",
    "        df = pd.DataFrame(json_data)\n",
    "        df = preprocess_data(df)\n",
    "        return df\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching synthetic data: {e}\")\n",
    "        return None\n",
    "    except ValueError as ve:\n",
    "        print(f\"Data extraction error: {ve}\")\n",
    "        return None\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"Extracts valid JSON array from API response.\"\"\"\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        match = re.search(r'\\[.*?\\]', response_text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(0))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON extraction failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Handles missing values and encodes categorical variables.\"\"\"\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else \"Unknown\")\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    return df\n",
    "\n",
    "def causal_analysis(api_key, df, target):\n",
    "    \"\"\"Performs causal analysis using LLM API.\"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Analyze the causal impact of {target} using the dataset: {df.to_json(orient='records')} Provide key causal relationships, estimated effects, and limitations.\"\n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": 0.7, \"max_tokens\": 1000}\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"Error in causal analysis.\"\n",
    "\n",
    "def intervention_analysis(api_key, df, target, intervention_col, intervention_value):\n",
    "    \"\"\"Performs intervention analysis to assess variable impact using Groq.\"\"\"\n",
    "    df_intervened = df.copy()\n",
    "    df_intervened[intervention_col] = intervention_value  \n",
    "    payload = {\"model\": \"llama3-70b-8192\", \"messages\": [{\"role\": \"user\", \"content\": f\"Assess the impact of changing {intervention_col} to {intervention_value} on {target} using the dataset: {df_intervened.to_json(orient='records')} Provide estimated causal effects and key insights.\"}], \"temperature\": 0.7, \"max_tokens\": 1000}\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers={\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"})\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"Error in intervention analysis.\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run synthetic data generation and analysis.\"\"\"\n",
    "    api_key = \"\"\n",
    "    domain = \"medicine\"\n",
    "    num_samples = int(input(\"Enter number of samples: \"))\n",
    "    df = generate_synthetic_data(api_key, num_samples, domain)\n",
    "    if df is not None:\n",
    "        print(df.head())\n",
    "        target = input(\"Enter target variable for analysis: \")\n",
    "        print(\"Performing causal analysis...\")\n",
    "        print(causal_analysis(api_key, df, target))\n",
    "        intervention_col = input(\"Enter intervention column: \")\n",
    "        intervention_value = input(\"Enter intervention value: \")\n",
    "        print(\"Performing intervention analysis...\")\n",
    "        print(intervention_analysis(api_key, df, target, intervention_col, intervention_value))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3977a21f-1ef1-42ee-ac48-3ab2404d873f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\n",
    "        \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \n",
    "        \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "def load_heart_disease_data(file_path):\n",
    "    \"\"\"Loads the Heart Disease dataset from a CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = preprocess_data(df)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_synthetic_data(api_key, num_samples, domain=\"medicine\"):\n",
    "    \"\"\"Generates synthetic data using the Groq API for a specified domain.\"\"\"\n",
    "    if domain not in DOMAIN_COLUMNS:\n",
    "        raise ValueError(f\"Unsupported domain: {domain}. Choose from {list(DOMAIN_COLUMNS.keys())}.\")\n",
    "    \n",
    "    schema = DOMAIN_COLUMNS[domain]\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    prompt = f\"Generate {num_samples} rows of structured synthetic data in JSON format with the following columns: {', '.join(schema)}. Return ONLY a valid JSON array. Ensure no missing values.\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 2000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        raw_data = response.json()\n",
    "\n",
    "        json_data = extract_json_from_response(raw_data[\"choices\"][0][\"message\"][\"content\"].strip())\n",
    "        if not json_data:\n",
    "            raise ValueError(\"Failed to extract valid JSON from response.\")\n",
    "\n",
    "        df = pd.DataFrame(json_data)\n",
    "        df = preprocess_data(df)\n",
    "        return df\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching synthetic data: {e}\")\n",
    "        return None\n",
    "    except ValueError as ve:\n",
    "        print(f\"Data extraction error: {ve}\")\n",
    "        return None\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"Extracts valid JSON array from API response.\"\"\"\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        match = re.search(r'\\[.*?\\]', response_text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group(0))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON extraction failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Handles missing values and encodes categorical variables.\"\"\"\n",
    "    # Fill missing values for numerical columns with median\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # Fill missing values for categorical columns with mode\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else \"Unknown\")\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "    return df\n",
    "\n",
    "def causal_analysis(api_key, df, target, max_rows=50):\n",
    "    \"\"\"Performs causal analysis using LLM API with a limited dataset to avoid large payloads.\"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    df_sample = df.head(max_rows)  \n",
    "\n",
    "    prompt = f\"Analyze the causal impact of {target} using this dataset: {df_sample.to_json(orient='records')} Provide key causal relationships, estimated effects, and limitations.\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        print(response)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"Error in causal analysis.\"\n",
    "\n",
    "def intervention_analysis(api_key, df, target, intervention_col, intervention_value):\n",
    "    \"\"\"Performs intervention analysis to assess variable impact using Groq.\"\"\"\n",
    "    df_intervened = df.copy()\n",
    "    df_intervened[intervention_col] = intervention_value \n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": f\"Assess the impact of changing {intervention_col} to {intervention_value} on {target} using the dataset: {df_intervened.to_json(orient='records')} Provide estimated causal effects and key insights.\"}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers={\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"})\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"Error in intervention analysis.\"\n",
    "\n",
    "def benchmark_analysis(api_key, df, target, intervention_col=None, intervention_value=None):\n",
    "    \"\"\"Benchmark causal and intervention analysis for real and synthetic data.\"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    causal_result = causal_analysis(api_key, df, target)\n",
    "    causal_duration = time.time() - start_time\n",
    "    \n",
    "    if intervention_col and intervention_value is not None:\n",
    "        start_time = time.time()\n",
    "        intervention_result = intervention_analysis(api_key, df, target, intervention_col, intervention_value)\n",
    "        intervention_duration = time.time() - start_time\n",
    "    else:\n",
    "        intervention_result = None\n",
    "        intervention_duration = 0\n",
    "\n",
    "    return {\n",
    "        \"causal_result\": causal_result,\n",
    "        \"causal_duration\": causal_duration,\n",
    "        \"intervention_result\": intervention_result,\n",
    "        \"intervention_duration\": intervention_duration\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run synthetic data generation, analysis, and benchmarking.\"\"\"\n",
    "    api_key = \"\"\n",
    "    domain = \"medicine\"\n",
    "    \n",
    "    file_path = input(\"Enter the file path of the heart disease dataset (CSV): \")\n",
    "    df = load_heart_disease_data(file_path)\n",
    "    \n",
    "    if df is None:\n",
    "        num_samples = int(input(\"Enter number of samples for synthetic data generation: \"))\n",
    "        df = generate_synthetic_data(api_key, num_samples, domain)\n",
    "    \n",
    "    if df is not None:\n",
    "        print(df.head())\n",
    "        \n",
    "        # Perform causal and intervention analysis for real data\n",
    "        target = input(\"Enter target variable for causal analysis: \")\n",
    "        print(\"Benchmarking causal and intervention analysis for real data...\")\n",
    "        real_data_results = benchmark_analysis(api_key, df, target)\n",
    "        print(real_data_results,\"rdf\")\n",
    "        # print(\"Real Data - Causal Analysis Results:\")\n",
    "        # print(real_data_results[\"causal_result\"])\n",
    "        # print(f\"Real Data - Causal Analysis Duration: {real_data_results['causal_duration']} seconds\")\n",
    "        \n",
    "        if real_data_results[\"intervention_result\"]:\n",
    "            print(\"hello\")\n",
    "            print(\"Real Data - Intervention Analysis Results:\")\n",
    "            print(real_data_results[\"intervention_result\"])\n",
    "            print(f\"Real Data - Intervention Analysis Duration: {real_data_results['intervention_duration']} seconds\")\n",
    "        \n",
    "#         # Perform causal and intervention analysis for synthetic data\n",
    "#         print(\"Benchmarking causal and intervention analysis for synthetic data...\")\n",
    "#         synthetic_data_results = benchmark_analysis(api_key, df, target)\n",
    "#         print(\"Synthetic Data - Causal Analysis Results:\")\n",
    "#         print(synthetic_data_results[\"causal_result\"])\n",
    "#         print(f\"Synthetic Data - Causal Analysis Duration: {synthetic_data_results['causal_duration']} seconds\")\n",
    "        \n",
    "#         if synthetic_data_results[\"intervention_result\"]:\n",
    "#             print(\"Synthetic Data - Intervention Analysis Results:\")\n",
    "#             print(synthetic_data_results[\"intervention_result\"])\n",
    "#             print(f\"Synthetic Data - Intervention Analysis Duration: {synthetic_data_results['intervention_duration']} seconds\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Unable to load or generate data. Exiting program.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5e73690-b796-417b-a705-5dabd8a6aaf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select a domain:\n",
      "1. medicine\n",
      "2. finance\n",
      "3. retail\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1/2/3...):  1\n",
      "Enter CSV file path (or press Enter to generate synthetic data):  heart.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_14324\\1770423233.py:117: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\saran\\AppData\\Local\\Temp\\ipykernel_14324\\1770423233.py:117: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter target variable for causal analysis:  cp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Causal Analysis on Real Dataset:\n",
      "To analyze the causal impact of 'cp' (chest pain type) on the target variable, we can use causal inference techniques. Before we dive into the analysis, let's first explore the dataset and identify potential confounding factors.\n",
      "\n",
      "**Descriptive Statistics**\n",
      "\n",
      "The dataset contains 30 observations with 14 variables, including the target variable. The 'cp' variable has three categories: 0, 1, and 2, which correspond to different types of chest pain.\n",
      "\n",
      "**Correlation Analysis**\n",
      "\n",
      "To identify potential confounding factors, let's perform a correlation analysis between 'cp' and other variables. We'll focus on correlations with a magnitude greater than 0.3.\n",
      "\n",
      "| Variable | Correlation with 'cp' |\n",
      "| --- | --- |\n",
      "| trestbps | -0.34 |\n",
      "| chol | -0.31 |\n",
      "| thalach | 0.36 |\n",
      "| exang | 0.32 |\n",
      "| oldpeak | 0.41 |\n",
      "| slope | 0.38 |\n",
      "\n",
      "These correlations suggest that 'cp' is associated with various physiological and exercise-related factors.\n",
      "\n",
      "**Causal Graph**\n",
      "\n",
      "Based on the correlations and domain knowledge, we can construct a causal graph to represent the relationships between 'cp' and other variables. Here's a simplified graph:\n",
      "\n",
      "```\n",
      "          +---------------+\n",
      "          |  Age  |\n",
      "          +---------------+\n",
      "                  |\n",
      "                  |\n",
      "                  v\n",
      "+---------------+       +---------------+\n",
      "|  Sex  |       |  FBS  |\n",
      "+---------------+       +---------------+\n",
      "                  |                       |\n",
      "                  |                       |\n",
      "                  v                       v\n",
      "+---------------+       +---------------+\n",
      "|  Trestbps  |       |  Chol  |\n",
      "+---------------+       +---------------+\n",
      "                  |                       |\n",
      "                  |                       |\n",
      "                  v                       v\n",
      "+---------------+       +---------------+\n",
      "|  Thalach  |       |  Exang  |\n",
      "+---------------+       +---------------+\n",
      "                  |                       |\n",
      "                  |                       |\n",
      "                  v                       v\n",
      "+---------------+       +---------------+\n",
      "|  Oldpeak  |       |  Slope  |\n",
      "+---------------+       +---------------+\n",
      "                  |                       |\n",
      "                  |                       |\n",
      "                  v                       v\n",
      "+---------------+\n",
      "|  CP  |\n",
      "+---------------+\n",
      "                  |\n",
      "                  |\n",
      "                  v\n",
      "+---------------+\n",
      "|  Target  |\n",
      "+---------------+\n",
      "```\n",
      "\n",
      "This graph suggests that 'cp' is influenced by age, sex, and various physiological factors. It also indicates that 'cp' affects the target variable, possibly through its relationships with exercise-related factors like thalach, exang, oldpeak, and slope.\n",
      "\n",
      "**Potential Confounding Factors**\n",
      "\n",
      "Based on the causal graph, we can identify the following potential confounding factors:\n",
      "\n",
      "1. Age\n",
      "2. Sex\n",
      "3. Trestbps\n",
      "4. Chol\n",
      "5. Thalach\n",
      "6. Exang\n",
      "7. Oldpeak\n",
      "8. Slope\n",
      "\n",
      "These variables may affect both 'cp' and the target variable, making it essential to control for them when estimating the causal effect of 'cp'.\n",
      "\n",
      "**Causal Effect Estimation**\n",
      "\n",
      "To estimate the causal effect of 'cp' on the target variable, we can use a causal inference method like propensity score matching or instrumental variable estimation. These methods can help us account for the confounding factors and isolate the causal relationship between 'cp' and the target variable.\n",
      "\n",
      "**Key Causal Relationships**\n",
      "\n",
      "Based on the analysis, we can identify the following key causal relationships:\n",
      "\n",
      "1. 'cp' is associated with various physiological and exercise-related factors, which in turn affect the target variable.\n",
      "2. The causal effect of 'cp' on the target variable is likely to be confounded by age, sex, and other physiological factors.\n",
      "3. Controlling for these confounding factors is essential to accurately estimate the causal effect of 'cp' on the target variable.\n",
      "\n",
      "By accounting for these relationships and confounding factors, we can gain a better understanding of the causal impact of 'cp' on the target variable.\n",
      "\n",
      "Causal Analysis on Synthetic Dataset:\n",
      "What a great dataset!\n",
      "\n",
      "After analyzing the dataset, I'll provide some insights on the causal impact of 'cp' (chest pain type) on the target variable, as well as potential confounding factors and key causal relationships.\n",
      "\n",
      "**Causal Impact of 'cp' on 'target'**\n",
      "\n",
      "The 'cp' variable has three categories: 1, 2, and 3. To estimate the causal impact of 'cp' on 'target', I'll use a simple linear probability model:\n",
      "\n",
      "`target ~ cp + ...`\n",
      "\n",
      "Where '...' represents other control variables.\n",
      "\n",
      "Using a linear probability model, I estimate the following coefficients:\n",
      "\n",
      "| Coefficient | Estimate | Std. Error | t value | Pr(>|t|) |\n",
      "| --- | --- | --- | --- | --- |\n",
      "| cp2 | 0.233 | 0.143 | 1.63 | 0.112 |\n",
      "| cp3 | 0.467 | 0.144 | 3.25 | 0.002 |\n",
      "\n",
      "The results suggest that:\n",
      "\n",
      "* Compared to 'cp' = 1, 'cp' = 2 is associated with a 23.3% increase in the probability of 'target' = 1 (p = 0.112).\n",
      "* Compared to 'cp' = 1, 'cp' = 3 is associated with a 46.7% increase in the probability of 'target' = 1 (p = 0.002).\n",
      "\n",
      "**Potential Confounding Factors**\n",
      "\n",
      "Upon reviewing the dataset, I identify the following potential confounding factors that may influence the relationship between 'cp' and 'target':\n",
      "\n",
      "1. **Age**: Older individuals may be more likely to experience chest pain and have a higher probability of 'target' = 1.\n",
      "2. **Sex**: Men and women may have different rates of chest pain and 'target' = 1.\n",
      "3. **Trestbps**: Resting blood pressure may be related to chest pain and 'target' = 1.\n",
      "4. **Chol**: Serum cholesterol levels may be associated with chest pain and 'target' = 1.\n",
      "5. **Fbs**: Fasting blood sugar levels may be related to chest pain and 'target' = 1.\n",
      "\n",
      "**Key Causal Relationships**\n",
      "\n",
      "Based on the dataset, I observe the following key causal relationships:\n",
      "\n",
      "1. **Chest pain type (cp)  Target**: The type of chest pain experienced by an individual affects their probability of having a heart disease (target = 1).\n",
      "2. **Age  Chest pain type (cp)**: Older individuals are more likely to experience chest pain, which in turn affects their probability of having a heart disease.\n",
      "3. **Sex  Chest pain type (cp)**: Men and women may have different rates of chest pain, which affects their probability of having a heart disease.\n",
      "4. **Trestbps  Chest pain type (cp)**: Higher resting blood pressure may lead to an increased risk of chest pain, which affects the probability of having a heart disease.\n",
      "5. **Chol  Chest pain type (cp)**: Higher serum cholesterol levels may contribute to an increased risk of chest pain, which affects the probability of having a heart disease.\n",
      "\n",
      "To better understand the causal relationships between these variables, additional analysis, such as causal graph estimation or instrumental variable analysis, may be necessary.\n",
      "\n",
      "Keep in mind that these findings are based on a simple analysis and should be interpreted with caution. Further exploration and validation of these results are recommended.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "DOMAIN_COLUMNS = {\n",
    "    \"medicine\": [\n",
    "        \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \n",
    "        \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"\n",
    "    ],\n",
    "    \"finance\": [\n",
    "        \"account_age\", \"transaction_amount\", \"transaction_type\", \"balance\", \"credit_score\", \"loan_approval\"\n",
    "    ],\n",
    "    \"retail\": [\n",
    "        \"customer_id\", \"product_id\", \"category\", \"price\", \"discount\", \"purchase\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "def load_dataset(file_path, domain):\n",
    "    \"\"\"Loads dataset from a CSV file and preprocesses it.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return preprocess_data(df, domain)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def generate_synthetic_data(api_key, num_samples, domain):\n",
    "    \"\"\"Generates synthetic data using the Groq API for a specified domain.\"\"\"\n",
    "    schema = DOMAIN_COLUMNS.get(domain, [])\n",
    "    if not schema:\n",
    "        print(\"Invalid domain selected.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    prompt = f\"Generate {num_samples} rows of structured synthetic data in JSON format with the following columns: {', '.join(schema)}. Return ONLY a valid JSON array.\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 2000\n",
    "    }\n",
    "\n",
    "    try:\n",
    " \n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()  # Raise an error for HTTP codes 4xx/5xx\n",
    "\n",
    "\n",
    "        response_text = response.json().get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "\n",
    "        json_data = extract_json_from_response(response_text)\n",
    "\n",
    "        return preprocess_data(pd.DataFrame(json_data), domain) if json_data else pd.DataFrame(columns=schema)\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching synthetic data: {e}\")\n",
    "        return pd.DataFrame(columns=schema)\n",
    "\n",
    "\n",
    "def extract_json_from_response(response_text):\n",
    "    \"\"\"Extracts and parses a valid JSON array from API response text.\"\"\"\n",
    "    json_start = re.search(r'\\[', response_text)  \n",
    "    if json_start:\n",
    "        response_text = response_text[json_start.start():] \n",
    "    \n",
    "    try:\n",
    "        json_data = json.loads(response_text)\n",
    "        if isinstance(json_data, list):  \n",
    "            return json_data \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"[DEBUG] Direct JSON parse error: {e}\")  \n",
    "\n",
    "    try:\n",
    "\n",
    "        match = re.search(r'\\[\\s*\\{.*?\\}\\s*\\]', response_text, re.DOTALL)\n",
    "        if match:\n",
    "            json_str = match.group(0)\n",
    "            return json.loads(json_str)  \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"[DEBUG] Regex JSON parse error: {e}\")  # Debug print\n",
    "\n",
    "    return None  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(df, domain):\n",
    "    \"\"\"Handles missing values and encodes categorical variables.\"\"\"\n",
    "    schema = DOMAIN_COLUMNS.get(domain, [])\n",
    "    if not schema:\n",
    "        return df\n",
    "\n",
    "    df = df[[col for col in schema if col in df.columns]]\n",
    "\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    for col in df.select_dtypes(include=[object]).columns:\n",
    "        df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else \"Unknown\", inplace=True)\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def causal_analysis(api_key, df, target):\n",
    "    \"\"\"Performs causal analysis using LLM API.\"\"\"\n",
    "    if target not in df.columns:\n",
    "        return f\"Error: Target variable '{target}' not found in dataset.\"\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    sample_data = df.head(25).to_json(orient='records')\n",
    "\n",
    "    prompt = f\"Analyze the causal impact of '{target}' using this dataset: {sample_data}. Provide key causal relationships and potential confounding factors.\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    except requests.exceptions.RequestException:\n",
    "        return \"Error in causal analysis.\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run dataset selection, synthetic data generation, and causal analysis.\"\"\"\n",
    "    api_key = \"\"  # Replace with your actual API key\n",
    "    \n",
    "    print(\"\\nSelect a domain:\")\n",
    "    for i, domain in enumerate(DOMAIN_COLUMNS.keys(), start=1):\n",
    "        print(f\"{i}. {domain}\")\n",
    "\n",
    "    try:\n",
    "        choice = int(input(\"Enter choice (1/2/3...): \").strip()) - 1\n",
    "        domain = list(DOMAIN_COLUMNS.keys())[choice]\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"Invalid selection. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    file_path = input(\"Enter CSV file path (or press Enter to generate synthetic data): \").strip()\n",
    "    real_df = load_dataset(file_path, domain) if file_path else None\n",
    "\n",
    "    synthetic_df = generate_synthetic_data(api_key, num_samples=25, domain=domain)\n",
    "\n",
    "    target_variable = input(\"\\nEnter target variable for causal analysis: \").strip()\n",
    "\n",
    "    if real_df is not None and not real_df.empty:\n",
    "        print(\"\\nCausal Analysis on Real Dataset:\")\n",
    "        print(causal_analysis(api_key, real_df, target_variable))\n",
    "    \n",
    "    if not synthetic_df.empty:\n",
    "        print(\"\\nCausal Analysis on Synthetic Dataset:\")\n",
    "        print(causal_analysis(api_key, synthetic_df, target_variable))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
